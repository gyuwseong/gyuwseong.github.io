{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"쿠버네티스 쿠버네티스(Kubernetes) 는 으로, 컨테이너 오케스트레이션(container orchestration) 툴이다. 쿠버네티스를 k8s 라고 줄여서 쓰길래 왜 그렇게 쓰나 했더니 이름에서 k 와 s 사이에 글자가 8개라서(...) 이렇게 쓴다고 한다. 쿠버네티스의 특징 서버 자원 클러스터링, 마이크로서비스 구조의 컨테이너 배포, 서비스 장애…","fields":{"slug":"/understanding-kubernetes/"},"frontmatter":{"date":"December 15, 2024","title":"Kubernetes 구성 요소 이해하기","tags":["Infrastructure","Kubernetes"]},"rawMarkdownBody":"\n## **쿠버네티스**\n\n쿠버네티스(Kubernetes) 는 `컨테이너화된 애플리케이션을 자동으로 배포, 관리, 확장할 수 있는 오픈소스 플랫폼`으로, 컨테이너 오케스트레이션(container orchestration) 툴이다. 쿠버네티스를 k8s 라고 줄여서 쓰길래 왜 그렇게 쓰나 했더니 이름에서 k 와 s 사이에 글자가 8개라서(...) 이렇게 쓴다고 한다.\n\n### **쿠버네티스의 특징**\n- 서버 자원 클러스터링, 마이크로서비스 구조의 컨테이너 배포, 서비스 장애 복구 등 컨테이너 기반의 서비스 운영에 필요한 대부분의 오케스트레이션 기능을 폭넓게 지원한다.\n- 영속적 볼륨, 스케줄링, 장애 복구, 오토 스케일링 등 컨테이너 기반의 클라우드를 운영할 때 필요한 대부분의 기능과 컴포넌트를 사용자가 직접 커스터마이징 할 수 있다.\n\n&nbsp;\n\n## **쿠버네티스 구성 요소**\n\n![출처: kubernetes.io](img2.svg)\n\n### **Pods**\n\n쿠버네티스에서 배포 및 실행이 가능한 가장 작은 구성 요소를 파드라고 한다. 파드는 하나 이상의 컨테이너로 이루어질 수 있고, 보통은 하나로 구성된다.\n`파드 하나당 고유한 IP 주소가 할당`되며 (컨테이너 하나당이 아니다) 같은 파드 내에 있는 컨테이너들은 localhost 로 통신하는데, 이는 각 파드가 하나의 네트워크 네임스페이스를 공유하기 때문이다. 파드의 내부 IP 주소를 통해 파드끼리의 통신이 가능하다. \n\n파드의 주요한 특성 중 하나는 Ephemeral 하다는 것인데, 해당 단어의 사전적 의미인 수명이 짧다는 뜻에서 알 수 있듯이 `파드는 일회용이고, 교체 가능한 자원이 되는 목적으로 생성`되었기 때문에 리소스 부족이나 장애, 버그로 인해 파드가 중단되면 해당 파드는 새로운 파드로 교체되고, IP 주소도 다시 할당된다.\n\n### **Service**\n서비스는 파드에 변경 사항이 생기면서 IP 주소가 재할당되는 것을 방지하여 파드에 고정적으로 접근할 수 있게끔 한다. 서비스와 파드는 일대일로 연결되어 있는데, 생명 주기는 일치하지 않기 때문에 `파드가 중단되더라도 서비스와 IP 주소는 변경되지 않게 된다.` 또한 서비스는 로드 밸런서 기능을 수행하여 다수의 파드로 트래픽을 분산시키는 역할도 한다.\n\n### **Ingress**\n인그레스는 클러스터 `외부의 트래픽을 내부 서비스로 전달하는 역할`을 하며, 외부 요청의 라우팅 규칙을 설정하여 외부 요청을 어떤 서비스로 라우팅할지 정의한다. 또한 가상 호스트 기반의 요청 처리가 가능하여 같은 IP 에 대해 다른 도메인 이름으로 요청이 도착해도 처리할 수 있다.\n\n\n### **ConfigMap**\n컨피그맵은 `공개되어도 되는 환경 변수에 한해 키-값 형식으로 저장하는 데 사용되는 API 오브젝트`이다. 컨피그맵을 통해 컨테이너와 환경을 분리하여 관리할 수 있다.\n컨피그맵을 사용하지 않으면서 환경 변수의 값을 변경하기 위해서는 보통 환경 변수가 정의된 파일을 수정 후, 레포지토리에 해당 파일을 푸시, 이미지 재빌드, 재배포하는 과정을 거쳐야 하지만 컨피그맵을 사용한다면 `컨피그맵 수정만으로도 환경 변수 수정이 가능`하다.\n\n### **Secret**\n컨피그맵은 기밀 데이터를 저장할 수 없기 때문에 비밀번호나 API 키 등의 기밀 데이터는 시크릿을 통해 저장한다. 시크릿은 데이터를 base64 인코딩을 통해 저장한다.\n\n### **Volumes**\n컨테이너는 일반적으로 stateless 하다. 이러한 특성 덕분에 이식성이 뛰어나지만, 앱의 특성에 따라 데이터를 저장해야 하는 경우도 있다. 이럴 때 사용되는 것이 볼륨인데, k8s 에서 볼륨은 로컬 스토리지 혹은 외부 스토리지로 나뉜다. 단, k8s 에서 데이터를 관리하는 것이 아니기 때문에 주의해야 한다.\n\n### **ReplicaSet**\n레플리카셋은 `일정 개수의 파드를 유지`할 수 있도록 해준다. 정해진 수의 동일한 파드가 항상 실행되도록 관리하고, 장애 등의 이유로 파드가 중단된다면 파드를 재생성한다.\n\n레플리카셋은 파드 개수를 관리하지만, 실제로 파드와 연결되어 있지는 않다. 파드와 레플리카셋은 `라벨 셀렉터를 통해 느슨하게 연결`되어 있는데, 특정 라벨을 가진 파드의 개수가 정해진 항목의 개수와 일치하지 않는다면 부족한 파드를 생성하게 된다. 만약 파드의 개수가 설정된 값보다 많다면 불필요한 개수만큼의 파드를 삭제하게 된다.\n\n### **Deployments**\n디플로이먼트는 `파드 생성시 파드의 상태를 정의`할 때 사용된다. 즉, 사용자가 파드를 생성하는 것이 아닌, 디플로이먼트를 통해 정의한대로 파드가 생성되는 것이다. 사용자는 디플로이먼트를 통해 파드를 관리하고, 설정할 수 있다. 단, 디플로이먼트는 stateless 한 앱을 배포할 때 사용되기 때문에 데이터베이스처럼 상태 유지가 필요한 앱에는 적합하지 않다.\n\n### **StatefulSets**\n따라서 상태 유지가 필요한 파드들은 스테이트풀세트를 통해 관리된다. 스테이트풀세트는 각 파드를 식별하기 위한 `고유한 이름을 지정하여 파드에 랜덤하게 접근하는 것이 아닌, 개별적으로 접근`할 수 있도록 한다. 또한, 영구적인 볼륨 마운트를 통해 데이터가 휘발되지 않고 보존되도록 한다.\n\n&nbsp;\n\n&nbsp;\n\n\n&nbsp;\n\n## **쿠버네티스 클러스터 구성 요소**\n\n&nbsp;\n\n\n![출처: kubernetes.io](img4.svg)\n\n### **Master Process**\n\nkube-apiserver, kube-scheduler, kube-controller-manager, etcd 등의 컴포넌트가 실행된다.\n\n- **kube-apiserver**: `사용자와의 통신이 이루어지는 컴포넌트`로, 일종의 게이트웨이 역할을 한다. 사용자가 쿠버네티스 클러스터 내에 명령을 내리면 최초로 요청을 받고, 해당 요청의 인증이 유효한지 검증 후 적절한 컴포넌트로 요청을 전달하는 역할을 한다.\n- **kube-scheduler**: `사용자가 요청한 파드를 클러스터 내의 적절한 워커 노드에 배치`하는 역할을 한다. 요청을 처리할 때는 각 노드의 리소스(CPU, 메모리 등) 를 토대로 결정하며, 노드의 리소스를 가장 효율적으로 사용할 수 있도록 최적의 노드를 선택한다.\n- **kube-controller-manager**: 클러스터에서 여러 컨트롤러를 관리하는 컴포넌트로, `클러스터 상태를 유지`하는 역할을 한다. 파드의 상태를 모니터링하고 중단된 파드의 재배치를 스케줄러에 요청하기도 한다.\n- **etcd**: 클러스터의 뇌와 같은 역할을 한다. 클러스터의 모든 변경 사항은 etcd 에 키-값 형태로 저장되는데, 이러한 데이터를 통해 `클러스터의 모든 구성 요소가 상태 정보를 공유하고, 변경 사항을 반영`할 수 있다.\n  - scheduler 는 etcd 에서 클러스터 상태를 읽고, 각 노드의 리소스를 확인하여 파드를 효율적으로 배치할 수 있다.\n  - controller-manager 는 etcd 에서 클러스터의 상태를 확인 후 필요한 컨트롤러에게 요청을 내리게 된다.\n\n&nbsp;\n\n### **Node Process**\n\nWorker Node 라고도 하며, 실제로 컨테이너화된 앱이 실행되는 곳이다. 각 워커 노드는 여러 프로세스를 실행하며, 이를 통해 앱을 관리한다. container runtime, kube-proxy, kubelet 등의 프로세스가 실행된다.\n\n- **kubelet**: 각 워커 노드에서 실행되는 에이전트로, `파드를 실행하고 관리`하는 역할을 한다. kubelet 은 노드에서 실행되는 컨테이너를 관리하며, 노드와 상호작용하여 파드의 상태를 지속적으로 모니터링한다.\n- **kube-proxy**: 네트워크 트래픽을 처리하는 프로세스로, 클러스터 내에서 서비스와 파드 간의 통신을 관리하며 로드 밸런싱 및 포트 포워딩 등을 담당한다.\n- **container runtime**: 파드 내부에서 컨테이너가 실행되므로 컨테이너 런타임이 필요하다. 대표적인 예로는 Docker, containerd, CRI-O 등이 있다.\n\n\n&nbsp;\n\n&nbsp;\n\n참고: [쿠버네티스 공식 문서](https://kubernetes.io/docs/home)"},{"excerpt":"몇 달 전에 개인 사용 용도로 크롬 확장 프로그램을 만든 이후로 요긴하게 잘 사용해 왔다. 최근에 공부에 쏟는 시간이 늘어나면서 특정 문서를 읽다가 해당 내용을 유튜브 검색을 통해 딥다이브 하게 되는 일이 잦아졌는데, 검색어를 복사하고 붙이는 과정 없이 바로 유튜브로 해당 검색어의 결과 페이지가 열리면 좋겠다고 생각했다. 아마도 간단한 작업일 것이라고 생…","fields":{"slug":"/quick-youtube-search-2/"},"frontmatter":{"date":"November 11, 2024","title":"확장 프로그램에 기능 추가하기","tags":["조각글"]},"rawMarkdownBody":"&nbsp;\n\n몇 달 전에 개인 사용 용도로 크롬 확장 프로그램을 만든 이후로 요긴하게 잘 사용해 왔다. 최근에 공부에 쏟는 시간이 늘어나면서 특정 문서를 읽다가 해당 내용을 유튜브 검색을 통해 딥다이브 하게 되는 일이 잦아졌는데, 검색어를 복사하고 붙이는 과정 없이 바로 유튜브로 해당 검색어의 결과 페이지가 열리면 좋겠다고 생각했다. 아마도 간단한 작업일 것이라고 생각해서 필요성을 느끼고 얼마 지나지 않아 기능을 추가하게 되었다.\n\n&nbsp;\n\n## _**개발 과정**_\n\n### _**manifest.json**_\n\n내가 원하는 기능은 검색어 드래그 후 오른쪽 클릭을 통해 메뉴를 열고, 검색을 진행하는 것이었기에 오른쪽 클릭 시 열리는 메뉴를 먼저 추가해야 했다. 해당 기능은 [contextMenus](https://developer.chrome.com/docs/extensions/develop/ui/context-menu) 라는 기능으로, `contextMenus` 를 추가하려면 가장 먼저 `manifest.json` 파일에 권한을 추가해야 한다.\n\n```json\n\"permissions\": [\n  \"contextMenus\"\n],\n\"icons\": {\n  \"16\": \"icon.png\",\n},\n```\n\n메뉴에 아이콘도 함께 보여주기 위해서 기존에 사용했던 아이콘도 함께 넣어주었다. 메뉴에 사용되는 아이콘의 크기는 16*16 이다.\n\n그다음에 설정해 줘야 하는 건 서비스 워커이다.\n\n&nbsp;\n\n### _**service worker**_\n\n서비스 워커는 브라우저 확장 프로그램의 중앙 이벤트 핸들러로, `contextMenus` API 작업의 로직도 처리할 수 있다. 검색어 드래그 후 오른쪽 클릭을 통해 메뉴를 열고 특정 메뉴 항목을 클릭하면 그에 대한 로직을 서비스 워커가 처리하는 식으로 동작한다. [Google Chrome Github](https://github.com/GoogleChrome/chrome-extensions-samples/blob/main/api-samples/contextMenus/basic/sample.js) 에서 서비스 워커 로직의 샘플을 확인할 수 있어서 참고했다.\n\n```javascript\nchrome.runtime.onInstalled.addListener(function () {\n    chrome.contextMenus.create({\n        id: \"myContextMenu\",\n        title: \"Search '%s'\",\n        contexts:[\"selection\"],\n    });\n});\n```\n`chrome.runtime.onInstalled.addListener` 를 통해 확장 프로그램이 설치 완료되면, [contextMenus.create](https://developer.chrome.com/docs/extensions/reference/api/contextMenus#method-create) 로 컨텍스트 메뉴를 생성해준다.\n\n&nbsp;\n\n\n![](img1.png)\n\n드래그로 선택된 텍스트에 대해서만 컨텍스트 메뉴가 표시되도록 하기 위해서 `contexts:[\"selection\"]` 를 설정해 주었는데, 이때 선택된 텍스트는 `%s` 를 통해서 가져올 수 있다.\n\n&nbsp;\n\n```javascript\nchrome.contextMenus.onClicked.addListener((info) => {\n    const selectedText = info.selectionText;\n    chrome.tabs.create({\n        url: `www.example=${encodeURIComponent(selectedText)}`\n    });\n});\n```\n`chrome.contextMenus.onClicked.addListener` 를 통해 메뉴 항목이 클릭되면 이벤트를 발생시키게 되는데, 이때 선택한 info 즉 [OnClickData](https://developer.chrome.com/docs/extensions/reference/api/contextMenus#type-OnClickData) 의 `selectionText` 로 선택된 텍스트를 가져와 필요한 처리를 해주게 된다.\n\n\n&nbsp;\n\n&nbsp;\n\n간단한 작업을 통해 필요한 기능을 성공적으로 추가 완료했다. 로직 파일이 두 개로 늘어났기 때문에 추후 ts 로 코드 변경을 진행하고, 유튜브 API 를 통해 검색어 자동완성 기능도 추가하면서 작은 확장 프로그램이지만 조금 더 좋은 사용성을 가질 수 있도록 지속적으로 개발할 예정이다.\n"},{"excerpt":"인덱스(Index)   특징 DBMS 에서 사용되는 인덱스는 자료 구조 중 하나인 SortedList 와 유사하다. SortedList 는 저장되는 값을 항상 정렬된 상태로 유지하는 자료구조로, DBMS 에서 사용되는 인덱스도 SortedList 와 마찬가지로 저장되는 칼럼의 값을 이용해 항상 정렬된 상태를 유지한다. 이러한 특징에 의해 여러 장단점이 존…","fields":{"slug":"/what-is-index/"},"frontmatter":{"date":"November 05, 2024","title":"인덱스 (Index)","tags":["Database"]},"rawMarkdownBody":"\n\n## **인덱스(Index)**\n\n&nbsp;\n\n### 특징\n\nDBMS 에서 사용되는 인덱스는 자료 구조 중 하나인 SortedList 와 유사하다. SortedList 는 저장되는 값을 항상 정렬된 상태로 유지하는 자료구조로, DBMS 에서 사용되는 인덱스도 SortedList 와 마찬가지로 저장되는 칼럼의 값을 이용해 항상 정렬된 상태를 유지한다.\n\n이러한 특징에 의해 여러 장단점이 존재하게 된다.\n\n- SortedList 는 데이터가 저장될 때마다 항상 값을 정렬해야 하므로 저장하는 과정이 복잡하고 느리지만, 이미 정렬되어 있기 때문에 원하는 값을 빨리 찾아올 수 있다. 이와 마찬가지로 DBMS 의 인덱스도 인덱스가 많은 테이블은 당연히 INSERT, UPDATE, DELETE 문의 처리가 느려진다. 하지만 이미 정렬되어 있기 때문에 `단순히 조회하는 용도인 SELECT 문은 매우 빠르게 처리`할 수 있다.\n- DBMS 에서 인덱스는 `데이터의 저장(INSERT, UPDATE, DELETE) 성능을 희생하고 그 대신 데이터의 읽기 속도를 높이는 기능`이라고 할 수 있다. 따라서 테이블에 인덱스를 추가할 때에는 데이터의 저장 속도와 읽기 속도를 비교하여 결정해야 한다. SELECT 쿼리문의 WHERE 조건절에 사용되는 컬럼이라고 해서 전부 인덱스로 생성하면 데이터 저장 성능이 떨어지고 인덱스의 크기가 비대해져 오히려 역효과만 불러올 수 있다.\n\n&nbsp;\n\n\n\n### 역할별 구분\n\n#### 프라이머리 인덱스 (Primary Index)\n\n프라이머리 인덱스는 데이터베이스 테이블에서 `레코드의 식별을 고유하게 보장하기 위해 사용되는 기본 인덱스`이다. 프라이머리 키(Primary Key) 와 연관되어 있으며, 해당 키가 인덱스로 설정된 것이기 때문에 NULL 값을 허용하지 않으며 중복을 허용하지 않는다. 대부분의 관계형 데이터베이스는 테이블을 생성할 때 프라이머리 키를 지정하면 자동으로 프라이머리 인덱스를 생성하기 때문에 별도로 인덱스를 만들지 않아도 된다.\n\n#### 세컨더리 인덱스 (Secondary Index)\n\n세컨더리 인덱스는 프라이머리 인덱스를 제외한 나머지 모든 인덱스를 말하며, `보조적으로 검색 성능을 향상시키는 역할`을 한다. 세컨더리 인덱스 중에서도 유니크 인덱스는 특정 컬럼이나 컬럼 조합에 대해 고유한 값만을 허용하도록 하는 인덱스이다. 프라이머리 인덱스와 성격이 비슷하지만, 프라이머리 인덱스는 한 테이블에 하나만 생성할 수 있는 반면 `유니크 인덱스는 여러 개 생성`할 수 있다. 또한, 프라이머리 키는 NULL 값을 허용하지 않지만, 유니크 인덱스는 일부 데이터베이스에서 NULL 값을 허용한다는 차이점이 있다.\n\n&nbsp;\n\n\n### 데이터 저장 방식(알고리즘)별 구분\n\n#### B-Tree 알고리즘\n\n가장 일반적으로 사용되는 인덱스 알고리즘으로, `칼럼의 값을 변형하지 않고 원래의 값을 이용해 인덱싱`하는 알고리즘이다. \n\n\n#### Hash 인덱스 알고리즘\n\n`칼럼의 값으로 해시값을 계산해서 인덱싱하는 알고리즘`으로, 매우 빠른 검색을 지원한다. 값을 변형해서 인덱싱하므로 전방(Prefix) 일치와 같이 값의 일부만 검색하거나 범위를 검색할 때는 해시 인덱스를 사용할 수 없다. \n\n&nbsp;\n\n&nbsp;\n\n## B-Tree 인덱스\n\n### 구조 및 특성\n\nB-Tree 는 트리 구조의 최상위에 하나의 `루트 노트`가 존재하고 그 하위에 자식 노드가 붙어 있는 형태다. 트리 구조의 가장 하위에 있는 노드를 `리프 노드`라 하고, 트리 구조에서 루트 노드도 아니고 리프 노드도 아닌 중간의 노드를 `브랜치 노드`라고 한다. 데이터베이스에서 인덱스와 실제 데이터가 저장된 데이터는 따로 관리되는데, `인덱스의 리프 노드는 항상 실제 데이터 레코드를 찾아가기 위한 주솟값을 가지고 있다.`\n\n![출처: scaler.com](img1.webp)\n\n위의 그림과 같이 인덱스의 키 값은 모두 정렬되어 있지만, 데이터 파일의 레코드는 정렬되어 있지 않고 임의의 순서로 저장되어 있다. `레코드가 삭제되어 빈 공간이 생기면 그 다음의 INSERT 는 가능한 한 삭제된 공간을 재활용하도록 설계`되어 있기 때문에 순서대로 저장되지는 않는다. \n\n인덱스는 테이블의 키 칼럼만 가지고 있으므로 나머지 칼럼을 읽으려면 데이터 파일에서 해당 레코드를 찾아야 한다. 이를 위해 인덱스의 리프 노드는 데이터 파일에 저장된 레코드의 주소를 가진다.\n\n&nbsp;\n\n### B-Tree 인덱스 키 추가 및 삭제\n\n#### 인덱스 키 추가\n\n새로운 키 값이 B-Tree 에 저장될 때 테이블의 스토리지 엔진에 따라 새로운 키 값이 즉시 인덱스에 저장될 수도 있고 그렇지 않을 수도 있다. B-Tree 에 저장될 때, 저장딜 키 값을 이용해 B-Tree 상의 적절한 위치를 검색해야 한다. 저장될 위치가 결정되면 레코드의 키 값과 대상 레코드의 주소 정보를 B-Tree 리프 노드에 저장한다. 이때 리프 노드가 꽉 차서 더이상 저장할 수 없을 경우 리프 노트가 분리되어야 하는데, 이는 상위 브랜치 노드까지 처리 범위가 넓어지게 된다. 이러한 작업 탓에 B-Tree 는 상태적으로 쓰기 작업, 즉 새로운 키를 추가하는 작업에 비용이 많이 드는 것으로 알려졌다.\n\n#### 인덱스 키 삭제\n\nB-Tree 의 키 값을 삭제할 때는 해당 키 값이 저장된 B-Tree 의 리프 노드를 찾아서 삭제 마크를 하면 된다. 이런식으로 삭제 마킹된 인덱스 키 공간은 계속 방치하거나 재활용할 수 있다.\n\n#### 인덱스 키 변경\n\n인덱스 키 값은 그 값에 따라 저장될 리프 노드의 위치가 결정되므로 B-Tree 의 키 값이 변경되는 경우에는 단순히 인덱스상의 키 값만 변경하는 것은 불가능하다. 결국 인덱스 키 값을 변경하는 작업은 `기존 인덱스 키 값을 삭제한 후 새로운 인덱스 키 값을 추가하는 작업`으로 처리된다.\n\n#### 인덱스 키 검색\n\n쓰기 작업을 할 때 인덱스 관리에 따르는 추가 비용을 감당하면서 인덱스를 구축해는 이유는 바로 빠른 검색을 위해서다. 인덱스를 검색하는 작업은 B-Tree 의 `루트 노드부터 시작해 브랜치 노드를 거쳐 최종 리프 노드까지 이동하면서 비교 작업을 수행`하는데, 이 과정을 `트리 탐색`이라고 한다. B-Tree 인덱스를 이용한 검색은 100% 일치 또는 값 앞부분만 일치하는 경우에 사용할 수 있다. \n\n인덱스의 키 값에 변형이 가해지면 변형된 값은 B-Tree 인덱스에 존재하는 값이 아니기 때문에 절대 B-Tree 의 빠른 검색 기능을 사용할 수 없다.\n\n&nbsp;\n\n### B-Tree 인덱스 사용에 영향을 미치는 요소\n\n#### 인덱스 키 값의 크기\n\n일반적으로 DBMS 의 B-Tree 는 자식 노드의 개수가 가변적인 구조인데, 이때 `자식 노드의 개수는 인덱스의 페이지 크기와 키 값의 크기에 따라 결정`된다. 인덱스 페이지에 키가 저장될 때, 키 값의 크기가 클수록 저장 가능한 인덱스 키의 개수가 자연스럽게 줄어들게 되고, 이는 한번에 읽을 수 있는 레코드 개수에 영향을 끼치게 된다. 결국 `인덱스를 구성하는 키 값의 크기가 커지면 디스크로부터 읽어야 하는 횟수가 늘어나고, 그만큼 느려진다`는 것을 의미한다.\n\n또한 인덱스 키 값의 길이가 길어진다는 것은 전체적인 인덱스의 크기가 커진다는 것을 의미한다. 인덱스를 캐시해두는 버퍼 풀이나 키 캐시 영역은 크기가 제한적이기 때문에 `하나의 레코드를 위한 인덱스 크기가 커지면 커질수록 메모리에 캐시해 둘 수 있는 레코드 수는 줄어든다.` 그렇게 되면 자연히 메모리의 효울이 떨어지는 결과를 가져온다.\n\n#### 데이터 선택도\n\n인덱스 선택도는 모든 인덱스 키 값 가운데 유니크한 값의 수를 의미한다. 인덱스 키 값 가운데 중복된 값이 많아지면 많아질수록 선택도는 떨어진다. 인덱스는 선택도가 높을수록 검색 대상이 줄어들기 때문에 그만큼 빠르게 처리된다.\n\n&nbsp;\n\n### B-Tree 인덱스를 통한 데이터 읽기\n\n#### 인덱스 레인지 스캔\n\n인덱스 레인지 스캔은 인덱스의 접근 방법 가운데 가장 대표적인 접근 방식으로, `검색해야 할 인덱스의 범위가 결정됐을 때 사용하는 방식`이다. 루트 노드에서부터 비교를 시작해 브랜치 노드를 거치고 최종적으로 리프 노드까지 찾아 들어가야만 비로소 필요한 레코드의 시작 지점을 찾을 수 있다. 일단 시작해야 할 위치를 찾으면 그때부터는 리프 노드의 레코드만 순서대로 읽으면 된다. 이 과정을 인덱스 스캔이라고 표현한다. 만약 스캔하다가 리프 노드의 끝까지 읽으면 리프 노드간의 링크를 이용해 다음 리프 노드를 찾아서 다시 스캔한다. 그리고 최종적으로 스캔을 멈춰야 할 위치에 다다르면 지금까지 읽은 레코드를 사용자에게 반환하고 쿼리를 끝낸다.\n\n#### 인덱스 풀 스캔\n\n인덱스 레인지 스캔과는 달리 `인덱스의 처음부터 끝까지 모두 읽는 방식`을 인덱스 풀 스캔이라고 한다. 대표적으로 쿼리의 조건절에 사용된 칼럼이 인덱스의 첫번째 칼럼이 아닌 경우 인덱스 풀 스캔 방식이 사용된다. 일반적으로 인덱스의 크기는 테이블의 크기보다 작으므로 직접 테이블을 처음부터 끝까지 읽는 것보다는 인덱스만 읽는 것이 효율적이다. `쿼리가 인덱스에 명시된 칼럼만으로 조건을 처리할 수 있는 경우 주로 이 방식이 사용`된다. 인덱스뿐만 아니라 데이터 레코드까지 모두 읽어야 한다면 절대 이 방식으로 처리되지 않는다. 먼저 인덱스 리프 노드의 제일 앞 또는 제일 뒤로 이동한 후, 인덱스의 리프 노드를 연결하는 연결리스트를 따라서 처음부터 끝까지 스캔하는 방식이다.\n\n#### 루스 인덱스 스캔\n\n말 그대로 느슨하게 인덱스를 읽는 것을 의미한다. 인덱스 레인지 스캔과 비슷하게 작동하지만 중간에 `필요치 않은 인덱스 키 값은 무시하고 다음으로 넘어가는 형태`로 처리한다.\n\n\n\n\n\n\n\n\n\n"},{"excerpt":"AWS 를 다룰 때, 특정 기능 구현에 필요한 리소스는 AWS 콘솔에서 쉽게 생성하여 테스트할 수 있다. 그러나 이번에 DynamoDB 를 처음 써보았기 때문에 ddb 를 사용하여 Lambda 를 트리거 하는 가장 간단한 방법인 stream 활성화를 로컬에서 테스트해 보고 싶었다. AWS 콘솔이 아닌 로컬에서 리소스 기능을 테스트하는 대표적인 방법에는 A…","fields":{"slug":"/localstack-testing/"},"frontmatter":{"date":"October 06, 2024","title":"Localstack 으로 DynamoDB + Lambda testing 해보기","tags":["AWS","Infrastructure"]},"rawMarkdownBody":"\nAWS 를 다룰 때, 특정 기능 구현에 필요한 리소스는 AWS 콘솔에서 쉽게 생성하여 테스트할 수 있다. 그러나 이번에 DynamoDB 를 처음 써보았기 때문에 ddb 를 사용하여 Lambda 를 트리거 하는 가장 간단한 방법인 stream 활성화를 로컬에서 테스트해 보고 싶었다.\n\nAWS 콘솔이 아닌 로컬에서 리소스 기능을 테스트하는 대표적인 방법에는 AWS SAM 을 사용하는 것이 있다.\nAWS SAM(Serverless Application Model) 은 AWS CloudFormation 의 확장 기능으로, `template.yaml` 에 정의된 SAM 템플릿은 내부적으로 CloudFormation 템플릿으로 변환되어 AWS 리소스를 배포하게 된다. 다만 이번 작업에서 핵심적으로 확인하고 싶은 기능인 ddb stream 은 SAM local 에서 테스트가 불가능하기 때문에 localstack 을 사용하기로 했다.\n\n&nbsp;\n\n## **Localstack**\n\n[Localstack 공식 문서](https://docs.localstack.cloud/user-guide/aws/dynamodbstreams/) 에 DynamoDB 생성 후 Lambda 와 연결까지 하는 과정이 잘 설명되어 있다.\n\n### **DynamoDB stream 활성화**\n\n처음 작업을 시작할 때, 이미 내 로컬에는 도커로 띄워둔 로컬 ddb 가 있는 상태였다. 따라서 localstack 에 ddb 부터 띄우는 것이 아니라, lambda 만 추가로 생성하여 이벤트 소스 연결 후, 테스팅하는 방법을 시도했다.\n\n&nbsp;\n\nddb 에 lambda 를 트리거 할 주체가 되는 테이블을 추가할 때, stream 을 활성화하는 옵션을 넣어야 한다.\n\n```json\n\"StreamSpecification\": {\n  \"StreamEnabled\": true,\n  \"StreamViewType\": \"NEW_AND_OLD_IMAGES\"\n}\n```\n\n- `StreamSpecification` 은 ddb 테이블의 stream 기능을 활성화하는 속성이다.\n- `StreamEnabled` 을 true 로 설정하면 stream 기능이 활성화되고, 테이블의 데이터 변경 사항을 스트림으로 기록할 수 있게 된다.\n- `StreamViewType` 은 스트림으로 기록되는 데이터 변경 사항의 종류를 지정하는 속성이다. 내 경우는 데이터 추가, 수정, 삭제 시를 기록하기 위해 `NEW_AND_OLD_IMAGES` 로 지정했다.\n\n&nbsp;\n\naws cli 명령어로 dynamoDB 테이블을 생성하면 테이블에 대한 정보를 볼 수 있는데, 이때 lambda 를 트리거 할 이벤트 소스를 얻을 수 있다.\n\n```bash\n\"LatestStreamArn\": \"arn:aws:dynamodb:ddblocal:000000000000:table/example-table/stream/2024-10-09T16:48:34.325\"\n```\n\n&nbsp;\n\n&nbsp;\n\n### **Localstack 실행**\n\nstream 활성화 옵션을 추가한 테이블이 생성되면, 해당 테이블이 트리거 할 lambda 를 localstack 환경에 생성하기 위해 localstack 을 docker 에 띄운다.\n\n```bash\ndocker run --rm -it \\\n  -e SERVICES=lambda \\\n  -p 4566:4566 \\\n  -p 4571:4571 \\\n  --name localstack localstack/localstack\n```\n\n위에서 언급했듯이 ddb 는 로컬에서 돌아가고 있었기에 Lambda 만 활성화하였다.\n\n&nbsp;\n\n```bash\nawslocal lambda create-function \\\n  --function-name processDynamoDBStream \\\n  --zip-file fileb://index.zip \\\n  --handler index.handler \\\n  --runtime nodejs18.x \\\n  --role arn:aws:iam::000000000000:role/lambda-role\n```\n\n실행 중인 localstack 에 lambda 함수를 processDynamoDBStream 라는 이름으로 생성해준다.\n\n&nbsp;\n\n```bash\nawslocal lambda create-event-source-mapping \\\n  --function-name processDynamoDBStream \\\n  --event-source-arn arn:aws:dynamodb:ddblocal:000000000000:table/example-table/stream/2024-10-09T16:48:34.325 \\\n  --batch-size 1 \\\n  --starting-position TRIM_HORIZON\n```\n\n해당 람다에 위의 stream arn 을 맵핑해준다.\n\n&nbsp;\n\n&nbsp;\n\n## **Local DynamoDB region 이슈**\n\n위의 과정을 거치면 아래의 에러 메세지를 확인할 수 있다.\n\n```bash\nWARN --- [et.reactor-0] l.aws.handlers.region\n: Region 'ddblocal' is not available. Resetting the region to 'us-east-1'.\nPlease consider using a region in the 'aws' partition to avoid any unexpected behavior.\nAvailable regions: ['af-south-1', 'ap-east-1', 'ap-northeast-1', 'ap-northeast-2',\n'ap-northeast-3', 'ap-south-1', 'ap-south-2', 'ap-southeast-1', 'ap-southeast-2',\n'ap-southeast-3', 'ap-southeast-4', 'ap-southeast-5', 'ca-central-1', 'ca-west-1',\n'eu-central-1', 'eu-central-2', 'eu-north-1', 'eu-south-1', 'eu-south-2', 'eu-west-1',\n'eu-west-2', 'eu-west-3', 'il-central-1', 'me-central-1', 'me-south-1',\n'sa-east-1', 'us-east-1', 'us-east-2', 'us-west-1', 'us-west-2']\n```\n\nlocalstack 은 aws 와 유사하게 동작하게 되므로, 람다와 연결하려는 arn region 이 aws 에 등록된 region 중 하나가 아니면 연결하지 못한다는 의미였다. region 변경을 시도했으나, `aws configure` 명령어를 통해 region 을 임의로 변경하더라도 도커로 ddb 를 띄우면 여전히 로컬에서의 region 은 고정되어 있었다. 따라서 localstack 으로 lambda 만 따로 생성하는 것이 아니라, ddb 부터 함께 생성하는 방식으로 방향을 변경했다.\n\n&nbsp;\n\n### **DynamoDB 와 Lambda 생성**\n\n```bash\ndocker run --rm -it \\\n  -e SERVICES=dynamodb,lambda \\\n  -p 4566:4566 \\\n  -p 4571:4571 \\\n  --name localstack localstack/localstack\n```\n\nlambda 와 dynamodb 둘 다 Localstack 에서 실행한다.\n\n&nbsp;\n\n동일하게 stream 활성화 옵션이 있는 테이블을 ddb 에 추가하면\n\n```bash\n\"LatestStreamArn\": \"arn:aws:dynamodb:us-east-1:000000000000:table/example-table/stream/2024-10-10T07:03:04.273\"\n```\n\n위의 arn 을 얻을 수 있다. 처음과 다른 점은 ddblocal 이 아닌, localstack 기본 region 인 `us-east-1` 이 적용되어 있다는 점이다.\n\n&nbsp;\n\nddb 에 테이블 추가 후, 위와 동일한 과정으로 lambda 함수 생성 후 arn 을 연결해 준다.\n\n![](img2.png)\n\n성공적으로 이벤트 소스가 맵핑되었고,\n\n&nbsp;\n\n![](img3.png)\n\nlocalstack gui 에서도 해당 정보를 확인할 수 있다.\n\n&nbsp;\n\n## **Docker network 이슈**\n\nddb 를 lambda 에 연결한 후, 정상적으로 lambda 가 invoke 되는지 확인하기 위해 테이블에 데이터를 저장했는데, 또 다른 이슈가 있었다.\n\n```bash\nERROR --- [et.reactor-2] l.services.lambda_.hints   :\nFailed to create the runtime executor for the function processDynamoDBStream.\nPlease ensure that Docker is available in the LocalStack container by adding\nthe volume mount \"/var/run/docker.sock:/var/run/docker.sock\" to your LocalStack startup.\nCheck out https://docs.localstack.cloud/user-guide/aws/lambda/#docker-not-available\n```\n\n에러 메세지에 있는 문서를 확인해 보니 현재 람다 함수가 local executor mode, 즉 로컬 실행 모드에서 실행 중인데, 이는 람다 함수가 도커를 사용하지 않고 localStack 컨테이너 내에서 직접 실행되는 모드를 의미하는 것이다. 따라서, localStack 을 실행할 때 Docker 소켓을 올바르게 마운트하도록 실행해 주면 문제를 해결할 수 있다.\n\n&nbsp;\n\n### **Docker 소켓 마운트**\n\n- Docker 데몬: [해당 링크](https://www.geeksforgeeks.org/what-is-docker-daemon/)에서 자세한 설명을 볼 수 있다. Docker 컨테이너를 관리하고 실행하는 핵심 컴포넌트라고 이해하면 된다.\n- Docker 소켓: Docker 데몬과의 통신을 위해 사용되는 Unix 소켓으로, 이 소켓을 통해 Docker 컨테이너는 호스트 시스템에서 실행 중인 Docker 데몬과 상호작용할 수 있다.\n- 마운트: Docker 컨테이너가 호스트 시스템의 파일이나 디렉터리에 접근할 수 있도록 연결하는 과정이다. 소켓 파일을 마운트하면, 컨테이너 내의 프로세스가 호스트의 Docker 데몬에 접근할 수 있다.\n- LocalStack 은 AWS Lambda 와 같은 기능을 에뮬레이션 하는 데 Docker 를 사용하므로 LocalStack 이 Lambda 함수를 Docker 환경에서 실행하기 위해서는 Docker 소켓에 접근할 수 있어야 한다.\n\n&nbsp;\n\n```bash\ndocker run --rm -it \\\n  --network sam \\\n  -e SERVICES=dynamodb,lambda \\\n  -p 4566:4566 \\\n  -p 4571:4571 \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  --name localstack localstack/localstack\n```\n\n`-v /var/run/docker.sock:/var/run/docker.sock` 옵션을 추가하여 localstack 을 실행한다. 이 옵션은 Docker 소켓 파일(/var/run/docker.sock)을 LocalStack 컨테이너 내의 동일한 경로에 연결한다. 이렇게 하면 LocalStack이 Docker를 사용하여 Lambda 함수를 실행할 수 있게 된다.\n\n&nbsp;\n\n옵션 변경 후 다시 람다를 invoke 하게 되면 정상적으로 테이블에 데이터가 저장되면서 람다가 invoke 됐음을 확인할 수 있다.\n\n![](img6.png)\n\n![](img4.png)\n\n`aws.putItem` 이 람다를 실행했고, 람다가 invoke 되어 로그가 찍혔음을 확인할 수 있다.\n"},{"excerpt":"스프링 컨테이너 스프링 컨테이너는 스프링에서 객체를 관리, 제공하는 역할을 한다. 스프링 컨테이너 생성 과정  는 스프링 컨테이너 역할을 하며, 스프링 프레임워크의 인터페이스 중 하나이다.  는  의 구현체인 클래스인데, 이름 그대로  기반의  를 토대로 스프링 애플리케이션 컨텍스트를 구성한다는 의미이다. 위의 코드는 컨테이너가 파라미터 없이 생성된 상태…","fields":{"slug":"/spring-container/"},"frontmatter":{"date":"June 23, 2024","title":"스프링 컨테이너와 빈","tags":["Spring"]},"rawMarkdownBody":"\n## **스프링 컨테이너**\n\n스프링 컨테이너는 스프링에서 객체를 관리, 제공하는 역할을 한다.\n\n### **스프링 컨테이너 생성 과정**\n\n```java\nApplicationContext applicationContext =\n  new AnnotationConfigApplicationContext();\n```\n\n- `ApplicationContext` 는 스프링 컨테이너 역할을 하며, 스프링 프레임워크의 인터페이스 중 하나이다.\n- `AnnotationConfigApplicationContext` 는 `ApplicationContext` 의 구현체인 클래스인데, 이름 그대로 `Annotation` 기반의 `config` 를 토대로 스프링 애플리케이션 컨텍스트를 구성한다는 의미이다.\n\n위의 코드는 컨테이너가 파라미터 없이 생성된 상태로, 아무 빈도 등록되어 있지 않기 때문에 `getBean()` 메서드를 호출하여 빈을 가져오면 예외가 발생할 수 있다. 보통은 파라미터로 설정 정보를 지정하고 스프링 컨테이너를 생성할 때 파라미터로 넘어온 설정 클래스 정보를 사용하여 스프링 빈을 등록한다.\n\n&nbsp;\n\n```java\n// AppConfig.java\n\n@Configuration\npublic class AppConfig {\n\n    @Bean\n    public MemberService memberService() {\n        return new MemberServiceImpl(memberRepository());\n    }\n\n    @Bean\n    public MemberRepository memberRepository() {\n        return new MemberMemoryRepository();\n    }\n\n    @Bean\n    public OrderService orderService() {\n        return new OrderServiceImpl(memberRepository(), discountPolicy());\n    }\n\n    @Bean\n    public DiscountPolicy discountPolicy() {\n        return new FixDiscountPolicy();\n    }\n}\n```\n\n위와 같이 `AppConfig.java` 파일이 존재할 때,\n\n```java\nApplicationContext applicationContext =\n  new AnnotationConfigApplicationContext(AppConfig.class);\n```\n\n`AnnotationConfigApplicationContext` 생성시 파라미터로 구성 정보를 지정해주면 스프링 컨테이너가 생성되면서 `AppConfig.class` 의 정보들을 사용하여 스프링 빈을 등록한다. 이때 스프링 컨테이너는 구성 정보를 토대로 스프링 빈 의존성을 주입한다. 위의 `AppConfig` 를 토대로 의존성을 주입하면,\n\n- `memberService <- memberRepository` : memberService 가 memberRepository 에 의존한다.\n- `orderService <- memberRepository, discountPolicy` : orderService 가 memberRepository, discountPolicy 에 의존한다.\n\n스프링 컨테이너는 빈을 생성하고 관리하는 역할을 하며, 빈이 생성되고 소멸되기까지의 생명 주기를 관리한다.\n\n&nbsp;\n\n### **빈 팩토리**\n\n`ApplicationContext` 를 살펴보면 `BeanFactory` 를 포함한 다양한 인터페이스를 상속받았음을 알 수 있다.\n\n![](img1.jpg)\n\nSpring 프레임워크에서 빈 팩토리는 `Spring IoC(Inversion of Control)` 컨테이너의 최상위 인터페이스 중 하나로, 애플리케이션에서 관리되는 객체인 `빈(bean)` 을 생성하고 관리하는 역할을 한다. 즉, `ApplicationContext` 가 빈 팩토리를 상속받았기 때문에 빈 관리 기능을 제공하는 것이다.\n\n&nbsp;\n\n&nbsp;\n\n## **스프링 빈**\n\n스프링 빈은 스프링에서 제공해주는 객체로, 스프링 컨테이너가 생성하고 관리한다.\n\n### **빈 등록 방식**\n\n스프링은 빈을 스프링 컨테이너에 등록하기 위해 XML 파일 설정, Annotation 등 다양한 방법을 제공하는데, 이때 `BeanDefinition` 을 사용한다. `BeanDefinition` 은 스프링 컨테이너가 관리하는 객체의 메타데이터를 담고 있는 인터페이스이다. 이를 통해 스프링은 빈의 생성, 초기화, 의존성 주입 등을 수행할 수 있다.\n스프링 컨테이너는 추상화된 `BeanDefinition` 를 기반으로 스프링 빈을 생성하기 때문에 설정 형식은 알 필요가 없다.\n\n![](img2.png)\n\n- `AnnotationConfigApplicationContext` 는 `AnnotatedBeanDefinitionReader` 를 사용해서 파라미터로 지정된 구성 정보를 읽고 `BeanDefinition` 을 생성한다.\n- 동일한 방식으로, 새로운 형식의 설정 정보가 추가되면, `~BeanDefinitionReader` 를 만들어서 `BeanDefinition` 을 생성하면 된다.\n\n&nbsp;\n"},{"excerpt":"문제 링크 문제에 설명된 절사평균이라는 개념을 잘 읽고 적용하면 풀릴 것 같은 문제지만, 파이썬에서 반올림에 흔히 사용되는  함수의 미묘한 특성을 알지 못하면 풀기 힘든 문제이다. round() 보통 우리가 보편적으로 알고 있는 반올림 방식은 숫자 5 이상부터 올리고, 4 이하부터 내리는 방식인데, 파이썬의 반올림은 가까운 짝수 쪽으로 반올림 하는 방식을…","fields":{"slug":"/boj-18110/"},"frontmatter":{"date":"June 18, 2024","title":"python round() 와 반올림","tags":["Algorithm","Python"]},"rawMarkdownBody":"\n[문제 링크](https://www.acmicpc.net/problem/18110)\n\n문제에 설명된 절사평균이라는 개념을 잘 읽고 적용하면 풀릴 것 같은 문제지만, 파이썬에서 반올림에 흔히 사용되는 `round()` 함수의 미묘한 특성을 알지 못하면 풀기 힘든 문제이다.\n\n## **round()**\n\n보통 우리가 보편적으로 알고 있는 반올림 방식은 숫자 5 이상부터 올리고, 4 이하부터 내리는 방식인데, 파이썬의 반올림은 가까운 짝수 쪽으로 반올림 하는 방식을 사용한다.\n\n![](img1.png)\n\n파이썬 쉘에 숫자를 실제로 입력해 보면 생각했던 결과가 나오지 않는 것을 알 수 있다.\n\n## **풀이**\n\n```python\nimport sys\n\ndef n_round(num):\n    return int(num) + (1 if num - int(num) >= 0.5 else 0)\n\nn = int(sys.stdin.readline())\nif n == 0:\n    print(0)\nelse:\n    lst = sorted([int(sys.stdin.readline()) for i in range(n)])\n    excl = n_round(n * 0.15)\n    print(n_round(sum(lst[excl:n - excl]) / (n - 2 * excl)))\n```\n\n`n_round` 함수를 통해 우리가 흔히 사용하는 반올림 방식을 적용시켜서 풀었다.\n\n&nbsp;\n\n여담으로 파이썬에서 사용하는 방식의 반올림을 `은행가 반올림 (Banker’s rounding)` 이라고 하는데, 통계적으로 확률 차이를 줄여주기 때문에 숫자와 돈에 민감한 금융가에서 사용한다고 한다. 또한 파이썬에서만 사용되는 방식도 아니고, C# 과 Java 에서도 이 방식을 사용하고 있다고 한다.\n"},{"excerpt":"백준 사이트에서 알고리즘 문제를 풀 때는 다른 알고리즘 풀이 사이트와 다르게 입출력을 명시해 줘야 한다. 가장 기본적인 입력 함수는  이고, 좀 더 빠른 입력을 위해 사용하는 함수는  이다. 두 함수의 속도 차이를 크게 느낄 수 있는 문제 하나를 예시로 들자면 단어 정렬 문제 링크 단순 문자열 정렬 유형으로, 어렵지 않은 난이도의 문제이다.   처음 풀이…","fields":{"slug":"/boj-1181/"},"frontmatter":{"date":"June 11, 2024","title":"input() vs sys.stdin.readline()","tags":["Algorithm","Python"]},"rawMarkdownBody":"\n백준 사이트에서 알고리즘 문제를 풀 때는 다른 알고리즘 풀이 사이트와 다르게 입출력을 명시해 줘야 한다. 가장 기본적인 입력 함수는 `input()` 이고, 좀 더 빠른 입력을 위해 사용하는 함수는 `sys.stdin.readline()` 이다.\n\n두 함수의 속도 차이를 크게 느낄 수 있는 문제 하나를 예시로 들자면\n\n## **단어 정렬**\n\n[문제 링크](https://www.acmicpc.net/problem/1181)\n\n단순 문자열 정렬 유형으로, 어렵지 않은 난이도의 문제이다.\n\n&nbsp;\n\n### **처음 풀이**\n\n```python\nn = int(input())\nlst = list(set([input() for i in range(n)]))\nlst.sort(key=lambda x: (len(x), x))\nfor s in lst:\n    print(s)\n```\n\n`input()` 함수로 숫자 n 을 입력 받고, n 만큼 루프를 돌려서 역시 `input()` 함수를 통해 문자열을 입력받고, 중복 제거 후 조건에 따라 람다식을 이용해서 정렬 후 차례대로 출력했다.\n\n&nbsp;\n\n### **두번째 풀이**\n\n```python\nimport sys\n\nn = int(sys.stdin.readline())\nlst = list(set([sys.stdin.readline().strip() for i in range(n)]))\nlst.sort(key=lambda x: (len(x), x))\nfor s in lst:\n    print(s)\n```\n\n시간이 생각보다 오래 걸리는 것 같아서 입력 함수만 변경한 풀이이다.\n\n&nbsp;\n\n두 풀이의 결과는 다음과 같다.\n\n&nbsp;\n\n![](img1.png)\n\n아래부터 첫 번째 풀이의 결과인데, 겨우 입력 함수만 변경했을 뿐인데 시간 차이가 무려 10배 가까이 났다.\n\n그냥 어렴풋이 `sys.stdin.readline()` 가 빠르다.. 정도만 인식하고 있었는데, 속도 차이가 급격하게 나는 것을 경험한 뒤로는 문제 풀 때 더 이상 기본 `input()` 함수는 사용하지 않고 있다. 뿐만 아니라, 시간제한 기준이 짧은 조금 더 어려운 난이도의 문제를 풀 때는 반드시 `sys.stdin.readline()` 함수를 사용해야 시간 초과가 나지 않았다.\n\n&nbsp;\n\n&nbsp;\n\n### **input()**\n\nide 에서 `input()` 의 설명을 찾아보면 다음과 같다.\n\n![](img2.png)\n\n외부로부터 입력을 받으면 문자열 끝에 오는 줄 바꿈 문자(\\n) 를 제거한다는 내용이다. 또한, 입력을 받기 전 보여주는 프롬포트 문자열을 출력할 수 있다. 또 한 가지 특징은 `input()` 함수는 입력의 끝 (EOF) 을 만났을 때 EOFError를 던져준다.\n\n&nbsp;\n\n&nbsp;\n\n### **sys.stdin.readline()**\n\nw3school 에서 `readline()` 의 정의를 찾아보면 다음과 같다.\n\n![](img3.png)\n\n외부로부터 입력을 받으면 한 줄을 그대로 읽어오기 때문에 줄 바꿈 문자(\\n) 를 따로 제거하지 않는다. 이러한 특성 때문에 문자열 입력을 여러 개 받을 때는 `strip()` 함수를 추가로 붙여서 줄 바꿈 문자를 제거하게끔 작성해야 한다.\n\n그리고 `input()` 함수와 달리 입력이 끝났어도 따로 에러를 던져주지 않기 때문에 아주 가끔 에러를 발생시켜야 통과되는 문제에서는 `input()` 함수를 사용해야만 한다.\n"},{"excerpt":"동기 처리와 비동기 처리 실행 컨텍스트  함수가 실행되려면  에서 생성된 함수 실행 컨텍스트가 실행 컨텍스트 스택에 푸시되어야 한다. 즉, 실행 컨텍스트 스택에 함수 실행 컨텍스트가 푸시되는 것은 바로 함수 실행의 시작을 의미한다. 함수가 호출된 순서대로 순차적으로 실행되는 이유는 함수가 호출된 순서대로 함수 실행 컨텍스트가 실행 컨텍스트 스택에 푸시되기…","fields":{"slug":"/asynchronous-programming/"},"frontmatter":{"date":"June 05, 2024","title":"비동기 프로그래밍","tags":["Javascript"]},"rawMarkdownBody":"\n## **동기 처리와 비동기 처리**\n\n### **실행 컨텍스트**\n\n![](img1.png)\n\n함수가 실행되려면 `함수 코드 평가 과정` 에서 생성된 함수 실행 컨텍스트가 실행 컨텍스트 스택에 푸시되어야 한다. 즉, 실행 컨텍스트 스택에 함수 실행 컨텍스트가 푸시되는 것은 바로 함수 실행의 시작을 의미한다. 함수가 호출된 순서대로 순차적으로 실행되는 이유는 함수가 호출된 순서대로 함수 실행 컨텍스트가 실행 컨텍스트 스택에 푸시되기 때문이다. 이처럼 함수 실행 순서는 실행 컨텍스트 스택으로 관리한다.\n\n자바스크립트 엔진은 단 하나의 실행 컨텍스트 스택을 갖는다. 이는 함수를 실행할 수 있는 창구가 단 하나이며, 동시에 2개 이상의 함수를 실행할 수 없다는 것을 의미한다. 실행 컨텍스트 스택의 최상위 요소인 \"실행 중인 실행 컨텍스트\" 를 제외한 모든 실행 컨텍스트는 모두 실행 대기 중인 태스크들이다. 대기 중인 태스크들은 현재 실행 중인 실행 컨텍스트가 팝되어 실행 컨텍스트 스택에서 제거되면, 즉 현재 실행 중인 함수가 종료하면 실행되기 시작한다. 자바스크립트 엔진은 한 번에 하나의 태스크만 실행할 수 있는 싱글 스레드 방식으로 동작하므로 처리에 시간이 걸리는 태스크를 실행하는 경우 블로킹(작업 중단)이 발생한다.\n\n&nbsp;\n\n### **동기(Synchronous) 처리**\n\n```javascript\n// sleep 함수는 일정 시간(delay)이 경과한 이후에 콜백 함수(func)를 호출한다.\nfunction sleep(func, delay) {\n  const delayUntil = Date.now() + delay;\n  while (Date.now() < delayUntil);\n  func();\n}\n\nfunction foo() {\n  console.log(\"foo\");\n}\n\nfunction bar() {\n  console.log(\"bar\");\n}\n\n// sleep 함수는 3초 이상 실행된다.\nsleep(foo, 3 * 1000);\n\n// bar 함수는 sleep 함수의 실행이 종료된 이후에 호출되므로 3초 이상 블로킹 된다.\nbar();\n\n// (3초 경과 후) foo 호출 -> bar 호출\n```\n\n위 예제의 sleep 함수는 3초 후에 foo 함수를 호출한다. 이때 bar 함수는 sleep 함수의 실행이 종료된 이후에 호출되므로 3초 이상(foo 함수의 실행 시간 + 3초) 호출되지 못하고 블로킹된다.이처럼 `현재 실행 중인 태스크가 종료할 때까지 다음에 실행될 태스크가 대기하는 방식을 동기(Synchronous)처리`라고 한다\n\n&nbsp;\n\n![](img5.png)\n\n동기 처리 방식은 태스크를 순서대로 하나씩 처리하므로 실행 순서가 보장된다는 장점이 있지만, 앞선 태스크가 종료할 때까지 이후 태스크들이 블로킹되는 단점이 있다.\n\n&nbsp;\n\n&nbsp;\n\n### **비동기(Asynchronous) 처리**\n\n```javascript\nfunction foo() {\n  console.log(\"foo\");\n}\n\nfunction bar() {\n  console.log(\"bar\");\n}\n\n// 타이머 함수 setTimeout은 일정 시간이 경과한 이후에 콜백 함수 foo를 호출한다.\n// 타이머 함수 setTimeout은 bar 함수를 블로킹하지 않는다.\nsetTimeout(foo, 3 * 1000);\nbar();\n// bar 호출 -> (3초 경과 후) foo 호출\n```\n\n`setTimeout` 함수는 위의 `sleep` 함수와 유사하게 일정 시간이 경과한 이후에 콜백 함수를 호출하지만 `setTimeout` 함수 이후의 태스크를 블로킹하지 않고 곧바로 실행한다. 이처럼 `실행 중인 태스크가 종료되지 않은 상태라 해도 다음 태스크를 곧바로 실행하는 방식은 비동기(Asynchronous)처리`라고 한다.\n\n&nbsp;\n\n![](img6.png)\n\n동기 처리 방식은 태스크를 순서대로 하나씩 처리하므로 실행 순서가 보장된다는 장점이 있지만, 앞선 태스크가 종료할 때까지 이후 태스크들이 블로킹 되어 처리 시간이 늘어날 수 있다는 단점이 있다. 비동기 처리 방식은 현재 실행 중인 태스크가 종료되지 않은 상태라 해도 다음 태스크를 곧바로 실행하므로 블로킹이 발생하지 않고 처리 시간이 단축된다는 장점이 있지만, 태스크의 실행 순서가 보장되지 않는다는 단점이 있다.\n\n&nbsp;\n\n&nbsp;\n\n## **이벤트 루프와 태스크 큐**\n\n### **싱글스레드인 자바스크립트의 비동기가 가능한 이유**\n\n자바스크립트의 특징 중 하나는 싱글 스레드로 동작한다는 것인데, 싱글 스레드는 한 번에 하나의 태스크만 처리할 수 있다는 것을 의미한다. 하지만 브라우저가 동작하는 것을 살펴보면 많은 태스크가 동시에 처리되는 것처럼 느껴진다. `자바스크립트의 동시성을 지원하는 것이 바로 이벤트 루프`이다. `이벤트 루프는 브라우저에 내장되어 있는 기능` 중 하나다.\n\n![](img4.png)\n\n대부분의 자바스크립트 엔진은 크게 2개의 영역으로 구분할 수 있다.\n\n### **콜 스택**\n\n소스코드 평가 과정에서 생성된 실행 컨텍스트가 추가되고 제거되는 스택 자료구조인 실행 컨텍스트 스택이 바로 콜 스택이다. 함수를 호출하면 함수 실행 컨텍스트가 순차적으로 콜 스택에 푸시되어 순차적으로 실행된다.\n\n### **힙**\n\n힙은 객체가 저장되는 메모리 공간으로, 콜 스택의 요소인 실행 컨텍스트는 힙에 저장된 객체를 참조한다. 메모리에 값을 저장하려면 먼저 값을 저장할 메모리 공간의 크기를 결정해야 한다. 객체는 원시 값과는 달리 크기가 정해져 있지 않으므로 할당해야 할 메모리 공간의 크기를 런타임에 결정(동적 할당)해야 한다. 따라서 객체가 저장되는 메모리 공간인 힙은 구조화되어 있지 않다는 특징이 있다.\n\n&nbsp;\n\n&nbsp;\n\n자바스크립트 엔진은 단순히 태스크가 요청되면 콜 스택을 통해 요청된 작업을 순차적으로 실행할 뿐이다. 비동기 처리에서 소스코드의 평가와 실행을 제외한 모든 처리는 자바스크립트 엔진을 구동하는 환경인 브라우저 또는 Node.js 가 담당한다. 이를 위해 브라우저 환경은 태스크 큐와 이벤트 루프를 제공한다.\n\n### **태스크 큐(task queue / event queue / callback queue)**\n\n`setTimeout` 이나 `setInterval` 같은 비동기 함수의 콜백 함수 또는 이벤트 핸들러가 일시적으로 보관되는 영역이다.\n\n### **이벤트 루프**\n\n콜 스택에 현재 진행 중인 실행 컨텍스트가 있는지, 태스크 큐에 대기 중인 함수(콜백 함수, 이벤트 핸들러 등)가 있는지 반복해서 확인한다. 만약 콜 스택이 비어있고 태스크 큐에 대기 중인 함수가 있다면 `이벤트 루프는 순차적으로(FIFO) 태스크 큐에 대기 중인 함수를 콜 스택으로 이동`시킨다. 이때 콜 스택으로 이동한 함수는 실행된다. 즉, 태스크 큐에 임시 보관된 함수들은 비동기 처리 방식으로 동작한다.\n\n```javascript\nfunction foo() {\n  console.log(\"foo\");\n}\nfunction bar() {\n  console.log(\"bar\");\n}\n\nsetTimeout(foo, 0); // 0초(실제는 4ms) 후에 foo 함수가 호출된다.\nbar();\n```\n\n위 예제의 실행 순서를 보면\n\n1. 전역 코드가 평가되어 전역 실행 컨텍스트가 생성되고 콜 스택에 푸시된다.\n\n2. 전역 코드가 실행되기 시작하여 `setTimeout` 함수가 호출된다. 이때 `setTimeout` 함수의 함수 실행 컨텍스트가 생성되고 콜 스택에 푸시되어 현재 실행 중인 실행 컨텍스트가 된다.\n\n3. `setTimeout` 함수가 실행되면 콜백 함수를 호출 스케줄링하고 종료되어 콜 스택에서 팝된다.\n\n   -> 이때 타이머를 설정하고 타이머가 만료되면 콜백 함수를 태스크 큐에 푸시하는 것(호출 스케줄링)은 브라우저의 역할이다.\n\n4. - 브라우저: 타이머를 설정하고 타이머의 만료를 기다린다. 이후 타이머가 만료되면 콜백 함수 `foo` 가 태스크 큐에 푸시된다.\n\n   - 자바스크립트 엔진: `bar` 함수가 호출되어 `bar` 함수의 함수 실행 컨텍스트가 생성되고 콜 스택에 푸시되어 현재 실행 중인 실행 컨텍스트가 된다. 이후 `bar` 함수가 종료되어 콜 스택에서 팝된다.\n\n5. 전역 코드 실행이 종료되고 전역 실행 컨텍스트가 콜 스택에서 팝된다. 이로서 콜 스택에는 아무런 실행 컨텍스트도 존재하지 않게 된다.\n\n6. 이벤트 루프에 의해 콜 스택이 비어 있음이 감지되고 태스크 큐에서 대기 중인 콜백 함수 `foo` 가 이벤트 루프에 의해 콜 스택에 푸시된다. 즉, 콜백 함수 `foo` 의 함수 실행 컨텍스트가 생성되고 콜 스택에 푸시되어 현재 실행 중인 실행 컨텍스트가 된다. 이후 `foo` 함수가 종료되어 콜 스택에서 팝된다.\n"},{"excerpt":"개인 코드 스타일을 드러낼 작은 프로젝트를 진행하면서, 기존에 사용했던 Sequelize 대신 Typeorm 을 적용해 보고 있다. 아직 시작한 지 얼마 되지 않아서 적응 중이고, 딥한 레벨의 로직을 구현하지 않았기 때문에 아주 큰 차이점을 느끼진 못했지만, ORM 에서 레이어 분리를 위해 자주 사용하는 repository 를 구현할 때의 차이점을 기록해…","fields":{"slug":"/custom-repository/"},"frontmatter":{"date":"June 04, 2024","title":"Custom repository 적용하기 (feat. Sequelize, TypeORM)","tags":["조각글"]},"rawMarkdownBody":"\n개인 코드 스타일을 드러낼 작은 프로젝트를 진행하면서, 기존에 사용했던 [Sequelize](https://sequelize.org) 대신 [Typeorm](https://typeorm.io) 을 적용해 보고 있다.\n\n아직 시작한 지 얼마 되지 않아서 적응 중이고, 딥한 레벨의 로직을 구현하지 않았기 때문에 아주 큰 차이점을 느끼진 못했지만, ORM 에서 레이어 분리를 위해 자주 사용하는 repository 를 구현할 때의 차이점을 기록해 보는 포스팅이다.\n\n## **Sequelize custom repository**\n\n```typescript\n// UserRepository.ts\n\n@Injectable()\nexport class UserRepository {\n  constructor(@InjectModel(User) private readonly repository: typeof User) {}\n\n  async findUserById(id: number): Promise<User> {\n    return this.repository.findByPk(id);\n  }\n}\n```\n\n- sequelize 에서는 `@Injectable()` 데코레이터를 통해 `UserRepository` 클래스를 NestJS 컨테이너에 등록하고 관리한다.\n- 클래스의 생성자에서 `@InjectModel(User)` 데코레이터를 사용하여 User 모델을 주입받는다.\n\n&nbsp;\n\n```typescript\n// UserModel.ts\n\n@Table({ tableName: 'user' })\nexport class User extends Model\n```\n\n- 이때 `@Table` 데코레이터를 통해 `User` 테이블과 `User` 모델이 맵핑되기 때문에 User 모델을 주입받을 수 있다.\n\n&nbsp;\n\n```typescript\n// UserModule.ts\n\n@Module({\n  imports: [SequelizeModule.forFeature([User])],\n  providers: [UserRepository],\n})\nexport class UseRepositoryModule {}\n```\n\n- `SequelizeModule.forFeature` 를 통해 repository 를 NestJS 모듈 DI 에 등록하면 다른 서비스나 모듈에서도 해당 repository 를 주입받아 사용할 수 있다.\n\n&nbsp;\n\n&nbsp;\n\n## **TypeORM custom repository**\n\n```typescript\n// UserRepository.ts\n\n@Injectable()\nexport class UserRepository extends Repository<User> {\n  constructor(private dataSource: DataSource) {\n    super(User, dataSource.createEntityManager());\n  }\n\n  async findOneById(id: number): Promise<User> {\n    return this.findOneBy({ id });\n  }\n}\n```\n\n해당 방식은 [여기](https://gist.github.com/anchan828/9e569f076e7bc18daf21c652f7c3d012?permalink_comment_id=4319458#gistcomment-4319458)에서 찾은 방식인데, 본문에 소개된 `@CustomRepository` 방식보다 더 직관적이고 깔끔해서 이 방식으로 적용했다.\n\n- `Repository` 클래스를 상속받는 자식 클래스에서 `DataSource` 를 주입 받고, 생성자를 호출하면서 `UserRepository` 를 생성한다.\n\n- TypeORM 은 repository 클래스를 생성 시 `EntityTarget` 과 `EntityManager` 를 생성하는데, `EntityTarget` 은 클래스가 다룰 타겟 `entity` 이고, `EntityManager` 는 데이터베이스 통신 작업을 수행하는 컴포넌트이다.\n\n- `DataSource` 는 데이터베이스 연결 및 `EntityManager` 생성을 관리하기 때문에 `DataSource` 를 주입받아서 `Custom Repository` 와 `EntityManager` 를 생성하고, 해당 `EntityManager` 를 통해 데이터베이스 작업을 수행하는 방식으로 동작한다.\n\n&nbsp;\n\n```typescript\n// UserModule.ts\n\n@Module({\n  imports: [TypeOrmModule.forFeature([User])],\n  providers: [UserRepository],\n})\nexport class UserModule {}\n```\n\n- `TypeOrmModule.forFeature` 를 통해 repository 를 NestJS 모듈 DI 에 등록하면 다른 서비스나 모듈에서도 해당 repository 를 주입받아 사용할 수 있다.\n"},{"excerpt":"최소비용 신장 트리 (MST, Minimum Spanning Tree) 무방향 (양수) 가중치 그래프면서 엣지들에 의해 그래프의 모든 정점들이 서로 연결되면서 가중치의 합이 최소가 되는 트리  사이클(cycle) 이 없는 연결된(connected) 무방향 그래프를 트리라고 한다. 우리가 보통 말하는 트리(ex 이진트리) 는 rooted tree 라고 부른…","fields":{"slug":"/minimum-spanning-tree/"},"frontmatter":{"date":"June 01, 2024","title":"최소비용 신장 트리 (Minimum Spanning Tree)","tags":["Data-structure"]},"rawMarkdownBody":"\n## **최소비용 신장 트리 (MST, Minimum Spanning Tree)**\n\n무방향 (양수) 가중치 그래프면서 엣지들에 의해 그래프의 모든 정점들이 서로 연결되면서 가중치의 합이 최소가 되는 트리\n\n![](img1.png)\n\n- 사이클(cycle) 이 없는 연결된(connected) 무방향 그래프를 트리라고 한다.\n- 우리가 보통 말하는 트리(ex 이진트리) 는 rooted tree 라고 부른다.\n- 가중치의 합이 최소이기 위해서는 싸이클이 없어야 하므로 MST 문제의 답은 항상 트리가 된다.\n- 노드가 n 개인 트리는 항상 n-1 개의 엣지를 가진다.\n- MST 는 유일하지 않다.\n\n## **Generic MST 알고리즘**\n\nMST 를 찾을 수 있는 두 가지 알고리즘 (Kruskal’s Algorithm, Prim’s Algorithm) 의 공통된 근본 알고리즘으로 **어떤 MST 의 부분집합 A 에 대해서 A 에 다른 엣지 (u, v) 를 추가해도 어떤 MST 의 부분집합이 될 경우 엣지 (u, v) 는 A 에 대해서 안전하다(safe)** 고 한다.\n\n![](img2.png)\n\n```graphql\n1. 처음에는 A 가 공집합이다.\n2. A 가 MST 가 되기 전까지 (엣지의 개수가 n-1 개가 되기 전까지)\n3. 안전한 엣지 (u, v) 를 찾아서\n4. A 와 합친다.\n5. 엣지의 개수가 n-1 개에 도달하면 A 를 반환한다.\n```\n\n&nbsp;\n\n### **안전한 엣지 찾기**\n\n![](img3.png)\n\n- 그래프의 정점들을 두 개의 집합 S 와 V-S 로 분할한 것을 **컷(cut)**(S, S-V) 라고 부른다.\n- 엣지 (u, v) 에 대해서 u 는 S 에 속하고 v 는 S-V 에 속할 때 엣지 (u, v) 는 컷(S, S-V)을 **cross 한다**고 한다.\n- 엣지들의 부분집합 A 에 속한 어떤 엣지도 컷(S, S-V) 를 cross 하지 않을 때 A 는 컷(S, S-V) 을 **존중한다(respect)**고 한다.\n- 만약 어떤 엣지의 값이 cut 을 가로지르는 엣지 중에 가장 작다면 그 엣지를 **가벼운 엣지(light edge)** 라고 부른다.\n\n&nbsp;\n\n### **증명**\n\nA 가 어떤 MST 의 부분집합이고, (S, V-S) 는 A 를 존중하는 컷이라고 할 때, 이 컷을 cross 하는 엣지들 중 가장 가중치가 작은 엣지 (u, v) 는 A 에 대해서 안전하다.\n\n![](img4.png)\n\n- A 가 어떤 MST 의 부분집합이므로 A 를 포함하는 MST 가 존재하며, MST 는 모든 정점이 연결되어 있어야 하므로 S 와 V-S 에 있는 A 의 엣지들을 잇는 엣지 e’ 가 존재한다고 가정한다.\n- 가중치가 가장 작은 엣지 (u,v) 를 e 라고 하면 w(e’) ≥ w(e) 이다.\n- 엣지 e’ 대신 e 를 A 의 일부로 삼아도 가중치의 합은 동일하거나 감소하게 된다.\n- MST 는 가중치의 합이 최소이므로 엣지 e 는 A 에 대해 안전하다.\n\n&nbsp;\n\n&nbsp;\n\n## **Kruskal 의 알고리즘**\n\n- 엣지들은 가중치의 오름차순으로 정렬한다.\n- 엣지들을 그 순서대로 하나씩 선택해 나간다. 단, 이미 선택된 엣지들과 사이클(cycle)을 형성하면 선택하지 않는다.\n- n-1 개의 엣지가 선택되면 종료한다.\n\n![](img5.png)\n\n### **증명**\n\n![](img6.png)\n\n- Kruskal 의 알고리즘의 임의의 한 단계를 생각해본다.\n- A 를 현재까지 알고리즘이 선택한 엣지의 집합이라고 하고, A 를 포함하는 MST 가 존재한다고 가정한다.\n- (S, V-S) 는 A 를 존중하는 컷이라고 할 때, 이 컷을 cross 하는 엣지들 중 가장 가중치가 작은 엣지 (u, v) 는 A 에 대해서 안전하다. → **Generic MST 알고리즘**\n- (S, V-S)를 cross 하는 엣지들 중 가장 가중치가 작은 엣지 (u, v) 가 Kruskal 의 알고리즘이 선택하는 엣지이므로 해당 엣지가 A 와 합쳐져도 A 는 여전히 MST 이다.\n\n&nbsp;\n\n### **사이클 검사**\n\n- 초기 상태 : 선택된 엣지 없음 (A 는 공집합)\n- 각각의 연결요소를 하나의 집합으로 표현한다.\n- 사이클은 이미 연결된 노드를 다시 연결할 때 생긴다.\n\n![](img7.png)\n\n![](img8.png)\n\n![](img9.png)\n\n![](img10.png)\n\n![](img11.png)\n\n![](img12.png)\n\n```graphql\n1. 처음에는 A 가 공집합이다.\n2. 그래프의 모든 정점 v 에 대하여\n3. 각각의 노드들을 유일한 원소로 가지는 집합을 만든다. (초기화)\n4. 엣지들을 가중치의 오름차순으로 정렬한다.\n5. 정렬된 엣지들을 가중치의 오름차순으로 하나씩 확인한다.\n6. 하나의 엣지에 있는 노드들이 각각 다른 집합에 속할 때\n7. A 에 해당 엣지를 추가한다.\n8. 각 노드가 속한 집합을 하나로 합친다.\n9. 엣지의 개수가 n-1 개에 도달하면 A 를 반환한다.\n```\n\n&nbsp;\n\n## **서로소 집합 (Disjoint Set)**\n\n![](img13.png)\n\n- 각 집합을 하나의 트리로 표현한다 → {1, 5}, {2, 4, 7, 10}, {3, 6, 8, 9}\n- 집합의 각 원소들이 트리의 노드가 되는데, 루트 여부나 부모 자식 관계도 상관이 없다.\n- 아래 → 위로 진행하는 상향식 트리이기 때문에 트리의 각 노드는 자식 노드가 아닌 부모 노드의 주소를 가진다.\n- 모든 트리를 하나의 배열로 표현한다.\n\n&nbsp;\n\n### **Find-Set(v)**\n\n자신이 속한 트리의 루트를 찾는다.\n\n![](img14.png)\n\n```graphql\n1. x 가 x 의 부모가 아니면\n2. x 의 부모가 속한 트리를 다시 검사한다.\n3. x 의 부모가 x 라면(x 가 트리의 루트라는 의미) x 의 부모를 반환한다.\n```\n\n&nbsp;\n\n### **Union-Set(u, v)**\n\n한 트리의 루트를 다른 트리의 루트의 자식 노드로 만든다.\n\n![](img15.png)\n\n![](img16.png)\n\n```graphql\n1. u 가 속한 트리의 루트 x 를 찾는다.\n2. v 가 속한 트리의 루트 y 를 찾는다.\n3. y 를 x 의 부모로 한다.\n```\n\n&nbsp;\n\n### **Weighted Union**\n\n두 집합을 합칠 때 트리의 높이를 낮게 유지해야 하므로 작은 트리의 루트를 큰 트리의 루트의 자식으로 만든다.\n\n![](img17.png)\n\n### **Path Compression (경로 압축)**\n\n특정 노드에서 트리의 루트까지 탐색할 때, 지나간 노드들을 투트 노드의 자식으로 붙여서 루트의 높이를 줄인다.\n\n![](img25.png)\n\n![](img19.png)\n\n## **Prim 의 알고리즘**\n\n- 임의의 노드를 출발 노드로 선택한다.\n- 출발 노드를 포함하는 트리를 점점 키워간다.\n- 매 단계에서 이미 트리에 포함된 노드와 포함되지 않은 노드를 연결하는 엣지들 중 가장 가중치가 작은 엣지를 선택한다.\n\n![](img20.png)\n\n### **증명**\n\n![](img21.png)\n\n- Prim 의 알고리즘의 임의의 한 단계를 생각해본다.\n- A 를 현재까지 알고리즘이 선택한 엣지의 집합이라고 하고, A 를 포함하는 MST 가 존재한다고 가정한다.\n- (S, V-S) 는 A 를 존중하는 컷이라고 할 때, 이 컷을 cross 하는 엣지들 중 가장 가중치가 작은 엣지 (u, v) 는 A 에 대해서 안전하다. → **Generic MST 알고리즘**\n- (S, V-S)를 cross 하는 엣지들 중 가장 가중치가 작은 엣지 (u, v) 가 Prim 의 알고리즘이 선택하는 엣지이므로 해당 엣지가 A 와 합쳐져도 A 는 여전히 MST 이다.\n\n&nbsp;\n\n### **가중치가 최소인 엣지 찾기**\n\n- VA : 이미 트리에 포함된 노드들\n- VA 에 아직 속하지 않은 각 노드 v 에 대하여 key 와 π 의 값을 유지한다.\n  - key(v) : 이미 VA 에 속한 노드와 자신을 연결하는 엣지들 중 가중치가 최소인 엣지 (u, v) 의 가중치\n  - π(v) : 엣지 (u, v) 의 끝점 u\n\n![](img22.png)\n\n- 가중치가 최소인 엣지 대신 key 값이 최소인 노드를 찾는다.\n- key 값이 최소인 노드 f 를 찾고, 엣지 (f, π(f)) 를 선택한다.\n\n![](img23.png)\n\n- 추가한 노드의 인접한 노드들 중 key 값이 더 작아지는 경우 갱신한다 → 노드 ~~d~~, g, e 의 값을 갱신한다.\n- 최소 우선순위 큐를 사용한다 → 노드들을 저장한 후, key 값이 최소인 노드를 삭제하고 반환한다.\n\n![](img24.png)\n\n```graphql\n1. 그래프의 모든 정점 v 에 대하여\n2. key 값을 무한대로 둔다.\n3. π 는 null 로 둔다. (초기화)\n4. 출발점 r 의 key 값을 0로 둔다.\n5. 모든 노드를 우선 순위 Queue 에 넣는다.\n6. Queue 가 비어있지 않은 동안에\n7. Queue 에서 최소값 u 를 찾는다.\n8. Queue 에서 u 의 인접한 노드 v 에 대하여\n9. v 가 아직 VA 에 속해있지 않으면서 u 의 키 값보다 엣지(u, v) 의 가중치가 작다면\n10. v 의 π 를 u 로 한다.\n11. v 의 key 를 엣지(u, v) 의 가중치로 한다.\n```\n"},{"excerpt":"why 몇 년 전부터 계속 블로그를 옮기고 싶었는데, 몇 가지 이유가 있었다. 기존에 사용하던 티스토리는 확장성에 제약이 많았고, 마크다운 형식이 편한 나에게 묘하게 호환되지 않는 티스토리 마크다운 방식이 불편했다. 나는 단순한 걸 좋아하고 뭐든지 파편화되어 있는 걸 싫어하는데, 공부할 때는 접근성이 편한 노션으로 공부를 하고, 코드를 작성할 때는 ide…","fields":{"slug":"/blog-migration/"},"frontmatter":{"date":"May 31, 2024","title":"블로그 옮기기","tags":["조각글"]},"rawMarkdownBody":"\n## **why**\n\n몇 년 전부터 계속 블로그를 옮기고 싶었는데, 몇 가지 이유가 있었다.\n\n1. 기존에 사용하던 티스토리는 확장성에 제약이 많았고, 마크다운 형식이 편한 나에게 묘하게 호환되지 않는 티스토리 마크다운 방식이 불편했다.\n2. 나는 단순한 걸 좋아하고 뭐든지 파편화되어 있는 걸 싫어하는데, 공부할 때는 접근성이 편한 노션으로 공부를 하고, 코드를 작성할 때는 ide 를 사용하고, 남에게 보여줄 만한 글을 작성할 때는 티스토리를 사용하는 게 불편했다.\n3. 그런 이유로 공부할 때 가장 많이 사용하는 노션을 블로그로 고려해 봤고, 그동안 공부한 내용들이 많이 쌓여 있었기 때문에 노션을 블로그로 연동한다면 여러모로 간편할 것 같았다. 그렇지만.. 노션의 가장 큰 단점인 `남이 보기 불편한 레이아웃` 때문에 노션을 블로그로 사용하는 건 포기했다.\n\n그래서 확장성을 갖추고, ide 에서 바로 내용을 정리해서 작성할 수 있고, 작성 방식에도 자유도가 높은 블로그를 직접 만들기로 했다.\n&nbsp;\n\n&nbsp;\n\n## **Jekyll vs Gatsby**\n\n좀 더 편해지자고 블로그를 옮기는 것이기에 많은 사람들이 이용하는 편한 방식의 블로그를 만들기로 했고, 가장 많이 사용하는 Jekyll 과 Gatsby 두 가지 방식이 추려졌다.\n\nJekyll 과 Gatsby 둘 다 보편적으로 많이 사용되는데, 둘 중에 하나를 선택하는 건 어렵지 않았다. 나는 루비를 잘 모르기 때문에 나에게 익숙한 Node.js 기반의 Gatsby 를 선택했고, 아주 좋은 선택이었다. 여러 시행착오가 있었지만 생각보다 수월하게 작업하여 배포까지 3시간 정도밖에 소요되지 않았다.\n&nbsp;\n\n&nbsp;\n\n## **오픈소스 활용**\n\n나는 프론트 지식이 거의 없고, 특히나 리액트에 대해서는 아는 게 전혀 없었기 때문에 만들어진 블로그 템플릿을 사용해서 블로그를 만들었다.\n내가 사용한 템플릿은 [devHudi 님의 템플릿](https://github.com/devHudi/gatsby-starter-hoodie/tree/main) 인데, 리드미에 서버 띄우는 방법부터 프로젝트 설정 방식까지 너무나도 친절하게 적혀 있어서 빠르고 간편하게 작업할 수 있었다. 디자인도 깔끔하고 군더더기 없고, 포스팅 목차 기능이나 태그 기능처럼 내가 필수적으로 원했던 기능도 포함되어 있어서 좋았다. 이 글을 보실 일은 없을 것 같지만.. 템플릿을 공유해 주신 devHudi 님께 감사의 말씀을 드리고 싶다.\n&nbsp;\n\n&nbsp;\n\n## **and**\n\n오랫동안 생각했던 과업을 달성했으니 이전 블로그에 있던 글들을 조금씩 옮겨오고, 노션에 적은 공부 글들도 옮겨올 생각이다.\n그리고 블로그를 배포하는 과정에서 종속성 문제로 좀 고생을 해서.. 그 기록도 추후에 남겨 봐야겠다.\n"},{"excerpt":"이번에 블로그를 옮기면서 gatsby 를 처음 사용해 봤는데, 큰 문제는 아니었어도 배포 과정에서 겪은 종속성 문제를 기록해보면 좋을 것 같단 생각이 들었다. 문제는 로컬 환경에서 잘 실행되는걸 확인한 프로젝트를 GitHub 에 푸시한 후, 정적 사이트를 호스팅할 수 있는 GitHub Pages 로 배포하는 과정에서 발생했다. gh-pages 는 프로젝트…","fields":{"slug":"/gatsby-version-ps/"},"frontmatter":{"date":"May 31, 2024","title":"종속성 문제 해결하기","tags":["조각글"]},"rawMarkdownBody":"\n이번에 블로그를 옮기면서 gatsby 를 처음 사용해 봤는데, 큰 문제는 아니었어도 배포 과정에서 겪은 종속성 문제를 기록해보면 좋을 것 같단 생각이 들었다.\n\n문제는 로컬 환경에서 잘 실행되는걸 확인한 프로젝트를 GitHub 에 푸시한 후, 정적 사이트를 호스팅할 수 있는 GitHub Pages 로 배포하는 과정에서 발생했다. [gh-pages](https://github.com/tschaub/gh-pages) 는 프로젝트를 GitHub Pages 에 쉽게 배포할 수 있도록 도와주는 패키지인데, 아주 예전에 팀 프로젝트를 진행할 때 사용해 본 경험이 있어서 또 해당 패키지를 사용하기로 했다.\n&nbsp;\n\n&nbsp;\n\n&nbsp;\n\n### **문제1: 프로젝트 Node version**\n\n![억장 와르르](img1.png)\n\n설치 시도를 하자마자 종속성 문제 에러가 발생했다. 내 로컬 환경 노드 버전이 좀 높기도 했고(20.버전이었다.), 보통 노드 버전 때문에 종속성 문제가 많이 발생하기 때문에 빠르게 레포 이슈를 검색했다.\n&nbsp;\n\n&nbsp;\n\n![](img2.png)\n\n예상처럼 노드 버전을 확인했고, 바로 14 버전으로 다운그레이드 시켜주었다.\n&nbsp;\n\n&nbsp;\n\n&nbsp;\n\n&nbsp;\n\n### **문제2: 패키지 Node version**\n\n다시 설치를 시도했는데, 이번에는 `ph-pages` 의 노드 버전이 안 맞는다는 에러가 발생했다. 갑자기 현업 때의 고통이 밀려왔다..\n&nbsp;\n\n&nbsp;\n\n![](img5.png)\n\n확인해 보니 노드 14 버전은 쓸 수 없다고 해서 고민을 했다. Netlify 같은 다른 배포 도구를 사용할지 다른 패키지를 찾아서 배포할지 고민하다 한번 노드 버전을 올려보기로 했고, 20 아래 버전 LTS 인 노드 18로 업그레이드를 해주었다.\n&nbsp;\n\n&nbsp;\n\n&nbsp;\n\n### **문제3: 패키지 의존성 충돌**\n\n![응 돌아가](img3.png)\n\n프로젝트 권장 노드 버전이 아니기 때문에 에러가 발생했고, 이제는 패키지 버전을 살필 차례였다. `gatsby-remark-katex` 는 `gatsby` 의 특정 버전(^2.0.0) 을 필요로 하는데, 현재 프로젝트에는 호환되지 않는 최신 버전(5.13.6) 의 `gatsby` 가 설치되어 있어서 발생하는 문제로 보였다. 단순히 생각했을 때는 패키지의 버전을 올리면 되지 않나 싶었는데, 뭔가 이유가 있어서 낮은 버전으로 사용되고 있을 것 같단 생각이 들었다.\n분명 같은 문제가 발생한 사람이 있을 것 같아서 또 레포로 달려가서(...) 검색을 해보니,\n&nbsp;\n\n&nbsp;\n\n&nbsp;\n\n![](img4.png)\n\ngatsby 5 마이그레이션 이후 볼드 처리 문제가 있어서 remark 패키지를 다운 그레이드 했다는 PR 기록이 있었다.\n&nbsp;\n\n&nbsp;\n\n&nbsp;\n\n### **요약**\n\n- 노드 버전 포기 -> 원하는 배포 방식 적용 불가능\n- 원하는 배포 방식 적용 -> 패키지 의존성 해결 불가능\n\n인 상황이었는데, 사실 패키지 의존성 문제가 발생해서 구글에 검색을 하면 `--legacy-peer-deps` 라는 특정 명령어로 임시 조치하라는 글들이 꽤나 많았기 때문에 해당 명령어로 해결할까 하는 생각도 들긴 했지만.. 현업에서 임시 조치의 부메랑을 맞아본 적이 있어서 조금 더 좋은 해결 방법을 찾고 싶었다.\n\n그래서 한 번 npm 말고 yarn 으로 설치해 볼까? 하는 생각이 들었고, 정말 놀랍게도 yarn 으로 해결이 되었다. (속도도 훨씬 빠른 건 덤..) 그동안 패키지 매니저 관련 글도 많이 봤고, 얼마 전에 토스 기술 블로그에서 [패키지 매니저 관련 글](https://toss.tech/article/lightning-talks-package-manager)도 봤지만, 실제로 패키지 매니저의 종류에 따라 개발에 차질이 생긴 건 처음이라 굉장히 좋은 경험이었다.\n\n하나 의문인 점은 로컬 환경에서 노드 20.13.1 버전으로 프로젝트를 빌드 할 때는 빌드가 잘 됐었는데, 코드를 푸시하고 다른 패키지 설치 시도를 하자마자 멀쩡히 돌아가던 패키지 에러가 발생한 점이다. 아직도 이유를 모르겠다..\n\n게다가 근본적인 종속성 문제를 해결한 건 아니기 때문에 추후에 gatsby 패키지 관련 이슈를 팔로업하면서 의존성 문제가 발생하지 않는 버전으로 업그레이드하는 방식으로 해결해 볼 생각이다.\n"},{"excerpt":"문제 링크 배열을 입력받아 합으로 0을 만들 수 있는 3개의 요소를 배열로 감싸서 출력하는 문제이다. 가장 처음 든 풀이법은 역시 브루트포스였지만 시간복잡도 때문에 타임아웃이 발생할 것 같아서 다른 방법으로 접근하기로 했고, 2Sum 풀 때처럼 투 포인터 방식으로 풀면 되겠다는 판단이 들었다. 첫번째 풀이  인풋 배열을 정렬시킨 후, 첫 수를 고정시키고 …","fields":{"slug":"/leetcode-3sum/"},"frontmatter":{"date":"May 18, 2024","title":"leetcode 15. 3Sum","tags":["Algorithm"]},"rawMarkdownBody":"\n[문제 링크](https://leetcode.com/problems/3sum/description/)\n\n배열을 입력받아 합으로 0을 만들 수 있는 3개의 요소를 배열로 감싸서 출력하는 문제이다.\n\n가장 처음 든 풀이법은 역시 브루트포스였지만 시간복잡도 때문에 타임아웃이 발생할 것 같아서 다른 방법으로 접근하기로 했고, 2Sum 풀 때처럼 투 포인터 방식으로 풀면 되겠다는 판단이 들었다.\n\n### _**첫번째 풀이**_\n\n![](img1.png)\n\n인풋 배열을 정렬시킨 후, 첫 수를 고정시키고 나머지 두 수를 첫 수의 바로 다음 수와 가장 마지막 수로 고정, 투 포인터 방식으로 단계별로 증감시키는 방식이다.\n\n첫 수를 고정시키고 나머지 수까지의 합을 구하는 방식이기 때문에 첫 수가 중복인 경우는 스킵했고, 수의 합을 0 과 비교해서 포인터를 이동시켰다.\n\n이 풀이의 문제점은 이 \\[-2,0,0,2,2\\] 처럼 포인터를 이동한 결과가 중복되는 경우를 처리하지 못 한다는 점이었다.\n\n&nbsp;\n\n### _**두번째 풀이**_\n\n![](img2.png)\n\n중복 추가되는 경우를 방지하기 위해 세 수의 합이 0인 경우, 포인터를 이동시켜서 동일 값 여부를 확인하는 코드를 추가했다.\n\n&nbsp;\n\n### _**세번째 풀이**_\n\n![](img3.png)\n\n좀 더 들여다보니 꼭 두개의 포인터 모두 이동시킬 필요는 없어서 오른쪽 포인터를 이동시키는 코드는 제거했다.\n"},{"excerpt":"예전부터 만들어야지 생각하면서 계속 미뤄뒀던.. 확장 프로그램을 드디어 만들어서 간략하게 개발 과정을 작성해 보는 포스팅이다. 개발 이유 이 조그만걸 왜 만들었냐면... 2019년부터 몇년간 잘 쓰던 확장 프로그램이 있었는데, 기능이 그렇게 많지 않았지만 나에게 딱 필요한 기능만 있었기에 아주 잘 쓰고 있었다. 그 확장 프로그램의 기능은 프로그램 아이콘을…","fields":{"slug":"/quick-youtube-search/"},"frontmatter":{"date":"April 17, 2024","title":"작고 귀여운 크롬 확장 프로그램 만들기","tags":["조각글"]},"rawMarkdownBody":"\n예전부터 만들어야지 생각하면서 계속 미뤄뒀던.. 확장 프로그램을 드디어 만들어서 간략하게 개발 과정을 작성해 보는 포스팅이다.\n\n## _**개발 이유**_\n\n이 조그만걸 왜 만들었냐면... 2019년부터 몇년간 잘 쓰던 확장 프로그램이 있었는데, 기능이 그렇게 많지 않았지만 나에게 딱 필요한 기능만 있었기에 아주 잘 쓰고 있었다.\n\n그 확장 프로그램의 기능은\n\n1.  프로그램 아이콘을 누르면 검색 팝업이 뜬다.\n2.  그 상태로 아무것도 검색하지 않고 엔터를 누르면 바로 새 탭이 열리며 유튜브 페이지로 이동된다.\n3.  검색창에 검색어를 치면 추천 검색어가 밑에 표시된다.\n4.  엔터를 누르면 유튜브에 해당 검색어를 검색한 결과가 새 탭으로 열리며 유튜브 페이지로 이동된다.\n\n정도로 아주 간단하고 군더더기 없었는데, 몇년간 정말 잘 썼었다. 하지만 그 뒤로 한차례의 대규모 크롬 업데이트를 거친 뒤에 더 이상 그 프로그램을 쓸 수 없게 되어서 다른 비슷한 유튜브 확장 프로그램을 사용했지만, 동일한 기능이 아니었기에 계속 작은 아쉬움이 있었고, 개발을 배운 뒤에는 내가 만들면 좋겠다는 생각을 늘 갖고 있었다.\n\n&nbsp;\n\n## _**개발 과정**_\n\n가장 먼저 [크롬 개발자 페이지](https://developer.chrome.com/docs/extensions?hl=ko&_gl=1*14e8fz3*_up*MQ..*_ga*MTY4MDgxMTk5LjE3MTMyNzAyMzA.*_ga_H1Y3PXZW9Q*MTcxMzI3MDIyOS4xLjAuMTcxMzI3MDIyOS4wLjAuMA.. \"크롬 개발자 페이지\")를 참고했다. 구글 캘린더 API 연동할 때 설명이 너무 불친절해서 조금 헤맸던 기억이 있었기에 긴장했는데, 개발 자체도 어렵지 않아 보였고, 설명도 잘 되어 있었다.\n\n### _**manifest.json**_\n\n노드에 package.json 이 있다면 크롬 확장 프로그램에는 manifest.json 이라는 파일이 필요한데, 기능이 그렇게 많은 프로그램이 아니라서 최소한으로 간단하게 작성했다.\n\n![](img1.png)\n\n이름도 정말 간단하게 Quick Youtube Search로 지었고, 아이콘을 누른 후 팝업창이 뜨면 검색하는 방식으로 동작하기에 연결되는 팝업 파일 이름도 popup.html로 지었다. 공식 문서에 따르면 2 버전은 올해 6월부터 deprecated 될 예정이고, 앞으로의 최신 표준 버전은 3 버전이기에 3 버전으로 적용시켰다.\n\n&nbsp;\n\n### _**popup.html & popup.css**_\n\nhtml 과 css를 정말 오랜만에 다뤄서 힘들었다. html 은 결제 연동 테스트할 때 샘플 페이지 띄우는 작업 때문에 종종 만져보긴 했지만 css는 그동안 사용한 적이 없어서 고생을 많이 했다.. 일부러 디자인이라고 할만한 요소조차 없게 만들었는데도 시간이 오래 걸렸다. 특히 간격 조정하느라 힘들었는데, 예전에 개발 처음 배울 때 padding 이랑 margin 때문에 고생했던 기억이 떠오르기도 했다.\n\n![](img2.png)\n\n![](img3.png)\n\n&nbsp;\n\n### _**popup.js**_\n\n동작 로직이 담겨 있는 파일이다. 내가 넣은 기능은 이전에 내가 잘 쓰던 프로그램의 기능과 유사한데, 아주 간단한 기능을 하나 추가했다.\n\n1.  프로그램 아이콘을 누르면 검색 팝업이 뜬다.\n2.  그 상태로 아무것도 검색하지 않고 엔터를 누르면 바로 새 탭이 열리며 유튜브 페이지로 이동된다.\n3.  엔터를 누르면 유튜브에 해당 검색어를 검색한 결과가 새 탭으로 열리며 유튜브 페이지로 이동된다.\n4.  팝업의 유튜브 아이콘을 누르면 새 탭이 열리며 유튜브 페이지로 이동된다. -> New!\n\n![](img4.png)\n\n이전 프로그램에 있었던 추천 검색어 기능을 넣으려고 찾아보니 유튜브에서 제공하는 API 가 따로 없고, 추천 검색어 결과를 받아서 내가 리스트 형태로 보여주는 방식으로 개발을 해야 했다. 사실 받아서 보여주는 것 자체는 문제가 없는데, 데이터가 보이도록 html&css 조정을 하는 과정이 정말 오래 걸릴 것 같았기에 아쉽지만 이 기능은 일단 포기할 수밖에 없었다. (추후 구현할 생각 매우 있음..)\n\n30줄 안팎의 짧은 코드였기에 js 로 간단하게 구현했지만, 브라우저 객체를 처음 다뤄보는 거였기에 타입 명시를 할 수 없어서 아쉬웠다. 아마 파일이 한 개만 더 있었어도 ts로 구현했을 것이다.\n\n&nbsp;\n\n&nbsp;\n\n### _**시행착오 1**_\n\n객체를 다루며 놓친 부분이 있었는데, 할당 방식이었다.\n\n![](img5.png)\n\n위의 경우는 searchParams 에 set의 반환값인 Null이 할당되므로\n\n![](img6.png)\n\n위의 방식처럼 해야 URLSearchParams 객체가 생성되고 searchParams에 할당된 후에, set 을 통해 값 세팅이 정상적으로 될 수 있었다.\n\n### _**시행착오 2**_\n\njs 코드를 자꾸 리팩토링하면서 만지다 보니 에러가 발생했는데, 코드를 아무리 봐도 뭐가 잘못된 건지 모르겠어서 디버깅 방법이 있나 찾아봤다. 찾아보니 크롬 확장 프로그램 관리페이지에서 오류 디버깅이 가능했고, 보기도 쉽고 편했다.\n\n![](img7.png)\n\n에러를 확인해보니 set 함수에 들어가야 할 매개변수가 string 타입이어야 했기에 생긴 오류였다. 이것 역시 타입 지정 언어였으면 놓치지 않았을 버그여서 아쉬웠지만, 큰 문제는 아니어서 다행이었다.\n\n&nbsp;\n\n&nbsp;\n\n## _**기타 디자인(?) 요소**_\n\n![](img8.png)\n\n내가 만든 확장 프로그램은 기능도 생김새도 아주 간단하지만 내 형편없는 마크업 실력 덕분에 구현에 시간이 꽤 오래 소요되었다. 그래도 내가 직접 만들기에 고를 수 있는 사소한 요소들이 있어서 소소한 즐거움이 되어주었다.\n\n### _**아이콘**_\n\n프로그램 아이콘과 팝업 검색창 아이콘은 같은 모양으로 맞추고 싶었고, 이전에 쓰던 프로그램 아이콘이 다른 확장프로그램 아이콘들과 크기가 달랐기 때문에 전체적으로 통일감을 주기 위해 크기를 맞추고 싶었는데, 팝업 검색창 아이콘과 동일한 디자인의 정방형 아이콘을 찾을 수 없었다. 그래도 최종적으로 선택된 정방형 아이콘도 깔끔하고, 다른 아이콘들과 크기가 비슷해서 통일감이 생겼다.\n\n### _**색**_\n\n원래 유튜브 로고색은 너무 빨갛게 느껴져서 아이콘의 채도를 살짝 낮추었다.\n\n### _**검색창**_\n\n검색창 인풋도 원래는 좀 더 포커스를 주고 싶어서 외곽 볼드 처리를 했었는데, 커서가 움직이는 것도 나름의 포커스고, 기본 형태가 나은 것 같아서 뺐다.\n&nbsp;\n\n&nbsp;\n\n## _**소감**_\n\n이게 뭐라고 아주 뿌듯하고 너무 재밌었다. 오랫동안 해야지 해야지 생각했던 건데 몇시간 만에 만들 수 있었던 거면 진작 할걸 하는 생각도 들었다. 알고리즘 이지 난이도조차 안 되는 로직에 정말 기본적인 마크업으로만 구성된 프로그램이지만 하나부터 열까지 온전히 내 입맛에 맞출 수 있어서 개발 내내 너무 신났다. (간단한 거라서 그렇게 신났을 수도..) 꽤 오랜 기간 동안은 메뉴바의 아이콘만 봐도 뿌듯할 것 같단 생각이 든다.\n\n&nbsp;\n\n&nbsp;\n\n&nbsp;\n\n참조\n\n[Mozilla doc](https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/manifest.json)\n\n[Chrome doc](https://developer.chrome.com/docs/extensions?hl=ko&_gl=1*14e8fz3*_up*MQ..*_ga*MTY4MDgxMTk5LjE3MTMyNzAyMzA.*_ga_H1Y3PXZW9Q*MTcxMzI3MDIyOS4xLjAuMTcxMzI3MDIyOS4wLjAuMA..)\n"},{"excerpt":"자바 아키텍처에는 3가지 구성요소가 있다.\n    \n  JDK(Java Development Kit) 자바 개발 키트는 자바 컴파일러, 디버거, 런타임 환경 등 자바 프로그램을 개발하고 실행하는데에 필요한 도구와 라이브러리를 제공한다. JRE(Java Runtime Environment) JVM 과 런타임 라이브러리 등으로 구성된 자바 어플리케이션을 실행…","fields":{"slug":"/understanding-jvm/"},"frontmatter":{"date":"April 15, 2024","title":"JVM 이해하기","tags":["Java"]},"rawMarkdownBody":"\n자바 아키텍처에는 3가지 구성요소가 있다.\n&nbsp;\n\n&nbsp;\n\n![](img1.png)\n&nbsp;\n\n### **JDK(Java Development Kit)**\n\n자바 개발 키트는 자바 컴파일러, 디버거, 런타임 환경 등 자바 프로그램을 개발하고 실행하는데에 필요한 도구와 라이브러리를 제공한다.\n\n### **JRE(Java Runtime Environment)**\n\nJVM 과 런타임 라이브러리 등으로 구성된 자바 어플리케이션을 실행할 환경이다.\n\n### **JVM(Java Virtual Machine)**\n\n**JVM(Java Virtual Machine, 자바 가상 기계)은 컴파일된 바이트 코드 파일을 운영체제에서 실행 가능한 기계어로 번역해서 실행할 수 있게 해주며, JRE(Java Runtime Env.) 의 일부**이다. 각 운영체제의 JVM 은 바이트 코드 파일을 해당 운영체제에서 실행 가능한 기계어로 번역해서 실행하기 때문에 **운영체제의 제약을 받지 않는 프로그램 개발이 가능**하다.\n&nbsp;\n\n&nbsp;\n\n이 중에서 오늘은 JVM 을 이해하는 것이 목적이다.\n&nbsp;\n\n&nbsp;\n\n![](img2.jpeg)\n\nJVM 에는 세가지 구성요소가 있다.\n\n1. 클래스로더 (Class Loader)\n2. 런타임 메모리 영역 (Runtime Data Area)\n3. 실행 엔진 (Execution Engine)\n\n## **클래스로더**\n\n클래스로더는 java.lang 패키지에 있는 추상 클래스로, .java 파일이 컴파일되어 바이트 코드를 포함한 동일한 이름을 가진 .class 파일이 생성되면 클래스로더가 .class 파일을 읽고 상응하는 이진 데이터를 생성해 JVM 내의 메서드 영역으로 동일한 이름의 클래스 파일을 로드한다.\n\n클래스로더는 **로딩(Loading) -> 링킹(Linking) -> 초기화(Initialization)** 의 순서로 작업을 수행한다.\n&nbsp;\n\n&nbsp;\n\n![](img3.png)\n\n### **로딩**\n\n클래스로더에는 몇가지 종류가 있으며 계층적으로 구성되어 있다.\n\n- 부트스트랩 클래스로더: **가장 먼저 실행되는 루트 클래스로더**로, $JAVA HOME/jre/lib directory 에서 표준 자바 패키지를 가져온다.\n- 익스텐션 클래스로더: 두번째로 실행되는 클래스로더로, 부트스트랩 클래스로더의 자식이자 어플리케이션 클래스로더의 부모이다. $JAVA_HOME/jre/lib/ext directory 에서 표준 자바 라이브러리를 가져온다.\n- 어플리케이션 클래스로더: 마지막으로 실행되는 클래스로더로, 익스텐션 클래스로더의 자식이다. 자바 어플리케이션 파일을 가져와서 실행한다.\n\n계층적 구조에 의해 클래스로더는 부모 클래스로더로부터 클래스를 로드하고 찾지 못할 경우 자식 클래스로더에게 로드를 위임하는 방식으로 동작한다. 이러한 클래스로더의 동작 방식은 **클래스의 중복 로딩을 방지하고 클래스 간의 의존성을 관리**하는 데에 도움이 된다.\n\n### **링킹**\n\n로딩 이후 클래스로더는 파일을 링킹한다. 이 과정에는 클래스로더가 파일을 검증, 준비, 해결하는 단계가 포함되어 있다.\n\n- 검증(verification): ByteCodeVerifier 라는 컴포넌트가 로딩된 .class 파일이 검증된 컴파일러에 의해 컴파일된건지, 구조가 유효한지 등을 검증한다. 검증이 실패하면 런타임 에러가 발생한다.\n- 준비(preparation): 만약 클래스에 인스턴스 요소나 정적 변수가 있다면 기본값을 할당한다.\n- 해결(resolution): 자바 클래스는 다른 클래스에 대한 참조를 포함할 수 있는데, 이러한 참조는 심볼릭 링크로 표현된다. 해결 과정에서 클래스로더는 심볼릭 링크를 직접적 링크로 대체한다.\n\n### **초기화**\n\n초기화 단계에서는 정적 변수를 초기화한다.\n&nbsp;\n\n&nbsp;\n\n---\n\n## **런타임 데이터 영역 (Runtime Data Area)**\n\n런타임 데이터 영역은 JVM 이 실행되는 동안 프로그램이 사용하는 데이터를 저장하는 메모리 영역으로,\n\n- 메서드 영역 (Method Area)\n- 힙 영역 (Heap Area)\n- 스택 영역 (Stack Area)\n- PC 레지스터 (Program Counter Register)\n- 네이티브 메서드 스택 (Native Method Stack) 의 다섯가지 영역으로 이루어져 있다.\n  &nbsp;\n\n  &nbsp;\n\n![](img4.jpeg)\n\n&nbsp;\n\n### **메서드 영역 (Method Area)**\n\n메서드, 필드, 상수 풀, 메타데이터 등의 클래스 정보를 저장하며, 모든 스레드가 공유하는 영역이다.\n\n런타임 상수 풀(Runtime Constant Pool) 이라는 자바 클래스 파일의 구성 요소가 존재하는데, 클래스 파일에 포함된 상수 풀(Constant Pool)의 런타임 버전이다. 즉, 클래스 파일에 정의된 상수들의 런타임 시점에서의 표현을 담고 있다. 자바 컴파일러가 소스 코드를 컴파일하여 클래스 파일을 생성할 때, 상수 풀은 클래스 파일에 상수 값들을 저장하고, 필요한 경우 런타임 중에 상수들을 참조하고 사용할 수 있도록 한다. 이를 통해 자바 프로그램은 동적으로 상수들을 참조하고 변경할 수 있다.\n&nbsp;\n\n&nbsp;\n\n### **힙 영역 (Heap Area)**\n\n![](img5.png)\n\n객체 인스턴스가 생성되는 영역으로, 동적으로 할당된 메모리를 저장한다. GC(Garbage Collection) 의 대상이 되는 메모리 영역으로, 더 이상 사용되지 않는 객체의 메모리를 회수한다. 힙 영역은 모든 스레드가 공유한다.\n\n- Young gen: 새롭게 생성된 클래스 인스턴스들이 저장된다.\n  - Eden: 새롭게 생성된 클래스 인스턴스들이 저장되는 곳으로, Eden 영역이 가득 차면, Minor GC(Garbage Collection) 가 발생하여 Eden 영역에 있는 살아있는 객체들을 체크하고, 살아남은 객체들은 Survivor 영역으로 이동된다. 이후 Eden 영역은 비워진다.\n  - Survivor: 이 영역에서 살아남은 객체들은 Old Generation 으로 이동될 수 있다.\n- Old gen: Young Gen 에서 일정 주기마다 살아남은 객체들이 이동하는 영역이다.\n\n  - 상대적으로 큰 메모리 공간을 가지고 있으며, 오랜 시간 동안 살아남은 객체들이 저장된다.\n  - Old Generation에 있는 객체들은 GC가 발생할 때마다 검사되며, 더 이상 참조되지 않는 객체들은 메모리에서 해제된다.\n\n&nbsp;\n\n### **스택 영역 (Stack Area)**\n\n메서드가 호출되면 새로운 스택 프레임이 생성되는데, 이 스택 프레임이 스택 영역에 저장된다. 메서드의 실행이 종료되거나 에러가 발생하면 스택에서 해당 프레임이 제거된다. 스택 영역은 각 스레드마다 하나씩 존재하며 스레드가 시작될 때 할당된다.\n\n### **PC 레지스터 (Program Counter Register)**\n\n현재 실행 중인 JVM 명령어의 주소를 저장한다. 각 스레드마다 별도로 할당되며, 스레드가 실행될 때마다 초기화된다.\n\n### **네이티브 메서드 스택 (Native Method Stack)**\n\n자바 외부에서 호출되는 네이티브 코드(C 나 C++ 로 작성된 코드) 를 실행하는 데에 사용되는 메모리 영역이다. 스택 영역과 마찬가지로 메서드를 호출할 때마다 해당 스택 프레임이 생성되며, 네이티브 메서드 실행이 종료되면 해당 스택 프레임이 제거된다.\n&nbsp;\n\n&nbsp;\n\n---\n\n## **실행 엔진 (Execution Engine)**\n\n실행 엔진은 JVM 내부에서 Java 바이트 코드를 해석하고 실행하는 역할을 하며\n\n- 인터프리터 (Interpreter)\n- JIT 컴파일러 (Just-In-Time Compiler)\n- GC (Garbage Collection) 으로 구성되어 있다.\n\n![](img6.png)\n\n### **인터프리터 (Interpreter)**\n\nJava 바이트 코드를 한 줄씩 읽어들여서 해당 코드를 직접 실행한다. 이 때문에 코드 실행 속도가 느릴 수 있다.\n\n### **JIT 컴파일러 (Just-In-Time Compiler)**\n\n인터프리터와 함께 사용된다. JIT 컴파일러는 인터프리터가 반복적으로 실행되는 코드를 감지하고, 해당 코드를 네이티브 기계 코드로 컴파일하여 최적화한다. 생성된 네이티브 코드는 캐시에 저장되어 동일한 코드가 실행될 때 재사용된다. 이를 통해 코드 실행 속도를 향상시킬 수 있다.\n\n### **GC (Garbage Collection)**\n\nGC는 JVM 에서 메모리 관리를 위해 사용되는 프로세스이다. GC는 주기적으로 메모리를 검사하여 사용되지 않는 객체를 식별하여 메모리를 해제한다. GC는 JVM 의 일부로 자동으로 실행되며, 개발자가 직접 관여할 필요가 없다.\n&nbsp;\n\n&nbsp;\n\n&nbsp;\n\n&nbsp;\n\n참조\n\nhttps://www.freecodecamp.org/news/jvm-tutorial-java-virtual-machine-architecture-explained-for-beginners/\nhttps://www.geeksforgeeks.org/jvm-works-jvm-architecture/\n"}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}